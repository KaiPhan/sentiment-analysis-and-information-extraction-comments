{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"experiment.ipynb","provenance":[],"collapsed_sections":["87NrC-3SG1pb","FLfiCckAHPWB","7k1WqTO59A5Z","CAnYaObi9HXf"],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"sMicb1TP98ji","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1640305614258,"user_tz":-420,"elapsed":18637,"user":{"displayName":"Quang Duy Trần","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvMaEX5IKcYvanQuv2HTQEdjP5mTCjGM4CkVJX=s64","userId":"16019943656023573816"}},"outputId":"0583ed8e-268c-468e-cc25-b85bd1f4d477"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive._mount('/content/drive')"]},{"cell_type":"code","source":["!pip install transformers seqeval[gpu] -q\n","!pip install fairseq -q\n","!pip install fastBPE -q\n","!pip install pytorch-crf -q"],"metadata":{"id":"if8rbToF-IbX","executionInfo":{"status":"ok","timestamp":1640305661058,"user_tz":-420,"elapsed":46807,"user":{"displayName":"Quang Duy Trần","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvMaEX5IKcYvanQuv2HTQEdjP5mTCjGM4CkVJX=s64","userId":"16019943656023573816"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"47a13c4b-84ea-4543-cfb9-c28209db8f39"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 3.4 MB 5.1 MB/s \n","\u001b[K     |████████████████████████████████| 43 kB 1.5 MB/s \n","\u001b[K     |████████████████████████████████| 596 kB 20.5 MB/s \n","\u001b[K     |████████████████████████████████| 61 kB 247 kB/s \n","\u001b[K     |████████████████████████████████| 3.3 MB 34.7 MB/s \n","\u001b[K     |████████████████████████████████| 895 kB 16.5 MB/s \n","\u001b[?25h  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[K     |████████████████████████████████| 1.7 MB 5.4 MB/s \n","\u001b[K     |████████████████████████████████| 90 kB 8.6 MB/s \n","\u001b[K     |████████████████████████████████| 145 kB 52.5 MB/s \n","\u001b[K     |████████████████████████████████| 74 kB 2.9 MB/s \n","\u001b[K     |████████████████████████████████| 112 kB 49.7 MB/s \n","\u001b[?25h  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for fastBPE (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/NLP/project_nlp"],"metadata":{"id":"cD7orqk4-HRv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1640305661059,"user_tz":-420,"elapsed":10,"user":{"displayName":"Quang Duy Trần","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvMaEX5IKcYvanQuv2HTQEdjP5mTCjGM4CkVJX=s64","userId":"16019943656023573816"}},"outputId":"32de2a3e-a2dd-4e17-e454-2ecbce1e5dad"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/NLP/project_nlp\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader, TensorDataset\n","from torchcrf import CRF\n","\n","from transformers import RobertaConfig, RobertaPreTrainedModel, RobertaModel, RobertaForTokenClassification\n","from transformers import AdamW, get_linear_schedule_with_warmup, get_constant_schedule\n","from transformers.modeling_outputs import TokenClassifierOutput\n","\n","import seqeval\n","from seqeval.metrics import classification_report, f1_score\n","\n","import pandas as pd\n","import numpy as np\n","import argparse\n","import time\n","import tqdm\n","\n","from fairseq.data.encoders.fastbpe import fastBPE\n","from fairseq.data import Dictionary\n","\n","from sklearn.utils.class_weight import compute_class_weight\n","\n","from src.dataset import *"],"metadata":{"id":"vQKjvZWT-LUa","executionInfo":{"status":"ok","timestamp":1640305671329,"user_tz":-420,"elapsed":10276,"user":{"displayName":"Quang Duy Trần","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvMaEX5IKcYvanQuv2HTQEdjP5mTCjGM4CkVJX=s64","userId":"16019943656023573816"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'"],"metadata":{"id":"usUDwbTOJ47L","executionInfo":{"status":"ok","timestamp":1640305671331,"user_tz":-420,"elapsed":7,"user":{"displayName":"Quang Duy Trần","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvMaEX5IKcYvanQuv2HTQEdjP5mTCjGM4CkVJX=s64","userId":"16019943656023573816"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["## DATA - HERE"],"metadata":{"id":"c0w2mvo-fF_X"}},{"cell_type":"code","source":["data = pd.read_csv('./data/joint/data_joint.csv')\n","data"],"metadata":{"id":"_tudmS6OfM9c","colab":{"base_uri":"https://localhost:8080/","height":423},"executionInfo":{"status":"ok","timestamp":1640305671978,"user_tz":-420,"elapsed":653,"user":{"displayName":"Quang Duy Trần","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvMaEX5IKcYvanQuv2HTQEdjP5mTCjGM4CkVJX=s64","userId":"16019943656023573816"}},"outputId":"4b66962f-7ce5-4d89-eeb3-7ec1a810d7c5"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-5f261319-c9e4-4ea0-ab8a-78824d5325ad\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>sentence</th>\n","      <th>word_labels</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>combo 3 cái giao có 1 cái , thành_ra đặt 6 cái...</td>\n","      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-DES,B-DE...</td>\n","      <td>-1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>mình mua áo có cổ màu trắng lại ship tới cho m...</td>\n","      <td>O,O,B-DES,B-DES,I-DES,B-DES,I-DES,O,O,O,O,O,B-...</td>\n","      <td>-1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>giao sai hàng . tôi muốn trả hàng . đặt be đậm...</td>\n","      <td>O,O,O,O,O,O,O,O,O,O,B-DES,I-DES,O,B-DES,I-DES</td>\n","      <td>-1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>sản_xuất việt_nam nhưng thấy in chữ trung_quốc...</td>\n","      <td>O,O,O,O,B-DES,I-DES,O,O,O,O,O,O,O</td>\n","      <td>-1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>mình đặt áo sơ_mi trắng dài tay mà shop giao c...</td>\n","      <td>O,O,B-DES,I-DES,B-DES,B-DES,I-DES,O,O,O,O,O,O,...</td>\n","      <td>-1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>3652</th>\n","      <td>3652</td>\n","      <td>chất_lượng sản_phẩm giống mô tả . giao hàng nh...</td>\n","      <td>O,O,O,O,O,O,O,O,O,O</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3653</th>\n","      <td>3653</td>\n","      <td>hài_lòng vô_cùng , giao nhanh , nhân_viên giao...</td>\n","      <td>O,O,O,O,O,O,O,O,O,O,O,B-DES,O,B-DES</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3654</th>\n","      <td>3654</td>\n","      <td>sản_phẩm ổn . giá phải_chăng . thật_sự là nhận...</td>\n","      <td>O,O,O,B-PRI,B-PRI,O,O,O,O,O,O,O,O,O,O,O,O,O</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3655</th>\n","      <td>3655</td>\n","      <td>hàng đẹp chuẩn chất_lượng . nếu áo có đai ngan...</td>\n","      <td>O,B-DES,O,O,O,O,B-DES,O,O,O,B-DES,O,B-DES,O,O,O</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3656</th>\n","      <td>3656</td>\n","      <td>vải mặc mát , dày_dặn . không có miếng mút ngự...</td>\n","      <td>B-DES,O,B-DES,O,B-DES,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3657 rows × 4 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5f261319-c9e4-4ea0-ab8a-78824d5325ad')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-5f261319-c9e4-4ea0-ab8a-78824d5325ad button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-5f261319-c9e4-4ea0-ab8a-78824d5325ad');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["      Unnamed: 0  ... label\n","0              0  ...    -1\n","1              1  ...    -1\n","2              2  ...    -1\n","3              3  ...    -1\n","4              4  ...    -1\n","...          ...  ...   ...\n","3652        3652  ...     1\n","3653        3653  ...     1\n","3654        3654  ...     1\n","3655        3655  ...     1\n","3656        3656  ...     1\n","\n","[3657 rows x 4 columns]"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","plt.figure(figsize=(20,10))\n","sns.barplot(x=data.sentence.apply(lambda x:len(x.split(' '))).value_counts()[:], y=data.sentence.apply(lambda x:len(x.split(' '))).value_counts()[:].index)\n","# data.sentence.apply(lambda x:len(x.split(' '))).value_counts()[:100].plot.bar()\n","plt.grid(True)\n","plt.title('Biểu đồ thể hiện phân bố độ dài câu bình luận')\n","plt.xlabel('')\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":608},"id":"k4fphU8_1Vpw","executionInfo":{"status":"ok","timestamp":1640306357525,"user_tz":-420,"elapsed":2570,"user":{"displayName":"Quang Duy Trần","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvMaEX5IKcYvanQuv2HTQEdjP5mTCjGM4CkVJX=s64","userId":"16019943656023573816"}},"outputId":"2161acfd-22b3-4d10-cc80-d0305f7b79ac"},"execution_count":30,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 1440x720 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["def plot_len_distribution(texts):\n","    plt.figure(figsize=(20, 10))\n","    plt.hist([len(text.split()) for text in texts], bins=100)\n","    plt.title('Token per text')\n","    plt.xlabel('Number of token')\n","    plt.ylabel('# samples')\n","    plt.grid(True)\n","    plt.show()\n","\n","plot_len_distribution(data.sentence)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":621},"id":"JgyHlNjH3xen","executionInfo":{"status":"ok","timestamp":1640306487432,"user_tz":-420,"elapsed":1304,"user":{"displayName":"Quang Duy Trần","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvMaEX5IKcYvanQuv2HTQEdjP5mTCjGM4CkVJX=s64","userId":"16019943656023573816"}},"outputId":"c902ae87-8b07-4748-b743-788df911503d"},"execution_count":34,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 1440x720 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["(data.sentence.apply(lambda x:len(x.split(' '))) > 128).sum()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kq3QWPWF5IcO","executionInfo":{"status":"ok","timestamp":1640306673047,"user_tz":-420,"elapsed":5,"user":{"displayName":"Quang Duy Trần","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvMaEX5IKcYvanQuv2HTQEdjP5mTCjGM4CkVJX=s64","userId":"16019943656023573816"}},"outputId":"13d6b5fe-93ed-47cb-af10-cd1ca169b682"},"execution_count":38,"outputs":[{"output_type":"execute_result","data":{"text/plain":["8"]},"metadata":{},"execution_count":38}]},{"cell_type":"markdown","source":["## Params"],"metadata":{"id":"38uoKuPKL0_4"}},{"cell_type":"code","source":["BATCHSIZE_TRAIN = 8\n","BATCHSIZE_VAL = 4\n","LEARNING_RATE = 5e-5\n","MAX_LEN = 128\n","NUM_EPOCH = 20\n","SEED = 42\n","NUM_CLASS = 5\n","MAX_GRAD_NORM = 1"],"metadata":{"id":"rgWrsDNLLz7N"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Data"],"metadata":{"id":"5Vo_jQIvM8sX"}},{"cell_type":"code","source":["parser = argparse.ArgumentParser()\n","parser.add_argument('--bpe-codes', \n","    default=\"./PhoBERT_base_transformers/bpe.codes\",\n","    required=False,\n","    type=str,\n","    help='path to fastBPE BPE'\n",")\n","args, unknown = parser.parse_known_args()\n","bpe = fastBPE(args)\n","\n","# Load the dictionary\n","vocab = Dictionary()\n","vocab.add_from_file(\"./PhoBERT_base_transformers/dict.txt\")\n","\n","labels_to_ids = {'B-DES': 1, 'B-PRI': 3, 'I-DES': 2, 'I-PRI': 4, 'O': 0, 'X': -100}\n","ids_to_labels = {0: 'O', 1: 'B-DES', 2: 'I-DES', 3:'B-PRI', 4:'I-PRI'}\n","\n","X, Y_label, Y_mask = convert_lines(\n","    data.sentence.values, \n","    data.word_labels.values, \n","    vocab, \n","    bpe, \n","    labels_to_ids, \n","    max_sequence_length=MAX_LEN)\n","\n","print('X shape: ', X.shape)\n","print('Y label shape', Y_label.shape)\n","print('Y mask shape', Y_mask.shape)\n","\n","train_size = 0.8\n","def train_test_split(data, train_size):\n","    X_df = pd.DataFrame(data)\n","    X_train = X_df.sample(frac = train_size, random_state=200)\n","    X_test = X_df.drop(X_train.index).reset_index(drop=True)\n","    X_train = X_train.reset_index(drop=True)\n","    return X_train.values, X_test .values\n","\n","X_train, X_test = train_test_split(X, train_size)\n","Y_label_train, Y_label_test = train_test_split(Y_label, train_size)\n","Y_mask_train, Y_mask_test = train_test_split(Y_mask, train_size)\n","\n","class_weight = compute_class_weight(\n","    class_weight='balanced', \n","    classes = np.array([0,1,2,3,4]), \n","    y=Y_label_train.flatten()[Y_label_train.flatten()>=0])\n","\n","print(class_weight)"],"metadata":{"id":"ao1LEzAfB6-P","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1640248483590,"user_tz":-420,"elapsed":2116,"user":{"displayName":"Quang Duy Tran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghu2xyMtK_2iyS9Voe4qtTbv8PTTDqItODbJlD0Uw=s64","userId":"16933642894382662697"}},"outputId":"ed019c16-e430-4eb2-dcdc-ebfbab6051ea"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 3657/3657 [00:01<00:00, 3393.82it/s]"]},{"output_type":"stream","name":"stdout","text":["X shape:  (3657, 128)\n","Y label shape (3657, 128)\n","Y mask shape (3657, 128)\n","[ 0.24328616  1.55779008  6.52840909 15.97682503 31.33636364]\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["train_dataset = TensorDataset(\n","    torch.tensor(X_train,dtype=torch.long), \n","    torch.tensor(Y_label_train,dtype=torch.long)\n","    )\n","valid_dataset = TensorDataset(\n","    torch.tensor(X_test,dtype=torch.long), \n","    torch.tensor(Y_label_test,dtype=torch.long)\n","    )\n","\n","train_loader = torch.utils.data.DataLoader(\n","    train_dataset, \n","    batch_size=BATCHSIZE_TRAIN, \n","    shuffle=True\n","    )\n","valid_loader = torch.utils.data.DataLoader(\n","    valid_dataset, \n","    batch_size=BATCHSIZE_VAL, \n","    shuffle=False\n","    )"],"metadata":{"id":"w-jI8GwDMJPw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Config"],"metadata":{"id":"8ObdUxfbMLgI"}},{"cell_type":"code","source":["class argu():\n","    def __init__(self):\n","        self.dict_path = \"./PhoBERT_base_transformers/dict.txt\"\n","        self.config_path = \"./PhoBERT_base_transformers/config.json\"\n","        self.max_sequence_length = MAX_LEN\n","        self.accumulation_steps = 1\n","        self.epochs = NUM_EPOCH\n","        self.seed = SEED\n","        self.bpe_codes = \"./PhoBERT_base_transformers/bpe.codes\"\n","args = argu()\n","\n","config = RobertaConfig.from_pretrained(\n","    args.config_path,\n","    output_hidden_states=True,\n","    return_dict=True,\n","    num_labels=NUM_CLASS,\n","    pad_token_id = 1,\n","    bos_token_id = 0,\n","    eos_token_id = 2,\n","    attention_probs_dropout_prob = 0.1,\n","    classifier_dropout=0.5,\n","    gradient_checkpointing=False,\n","    hidden_act=\"gelu\",\n","    hidden_dropout_prob=0.1,\n","    hidden_size=768,\n","    initializer_range=0.02,\n","    intermediate_size=3072,\n","    layer_norm_eps=1e-05,\n","    max_position_embeddings=258,\n","    model_type=\"roberta\",\n","    num_attention_heads=12,\n","    num_hidden_layers=12,\n","    position_embedding_type=\"absolute\",\n","    tokenizer_class=\"PhobertTokenizer\",\n","    transformers_version=\"4.15.0\",\n","    type_vocab_size=1,\n","    use_cache=True,\n","    vocab_size=64001\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"klKRUc99MNYH","executionInfo":{"status":"ok","timestamp":1640248514674,"user_tz":-420,"elapsed":6,"user":{"displayName":"Quang Duy Tran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghu2xyMtK_2iyS9Voe4qtTbv8PTTDqItODbJlD0Uw=s64","userId":"16933642894382662697"}},"outputId":"2fefb51c-5142-4ae8-c6eb-d6cbb5d7804e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["You are using a model of type bert to instantiate a model of type roberta. This is not supported for all configurations of models and can yield errors.\n"]}]},{"cell_type":"code","source":["def train(epoch, verbose = False):\n","    tr_loss, tr_accuracy = 0, 0\n","    nb_tr_examples, nb_tr_steps = 0, 0\n","    tr_preds, tr_labels = [], []\n","    # put model in training mode\n","    model.train()\n","    \n","    for idx, batch in enumerate(train_loader):\n","        ids, labels = batch\n","        ids = ids.to(device)\n","        labels = labels.to(device)\n","        mask = ids!=1\n","\n","        outputs = model(input_ids=ids, attention_mask=mask, labels=labels)\n","        loss = outputs[0]\n","        \n","        tr_logits = outputs[1]\n","        tr_loss += loss.item()\n","\n","        nb_tr_steps += 1\n","        nb_tr_examples += labels.size(0)\n","        \n","        if idx % 100==0 and verbose:\n","            loss_step = tr_loss/nb_tr_steps\n","            print(f\"Training loss per 100 training steps: {loss_step}\")\n","           \n","        # compute training accuracy\n","        flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n","        active_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n","        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n","        \n","        # only compute accuracy at active labels\n","        active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n","        \n","        labels = torch.masked_select(flattened_targets, active_accuracy)\n","        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n","        \n","        tr_labels.extend(labels)\n","        tr_preds.extend(predictions)\n","    \n","        # gradient clipping\n","        torch.nn.utils.clip_grad_norm_(\n","            parameters=model.parameters(), max_norm=MAX_GRAD_NORM\n","        )\n","        \n","        # backward pass\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        try: \n","            scheduler0.step()\n","        except:\n","            scheduler.step()\n","\n","    epoch_loss = tr_loss / nb_tr_steps\n","    tr_accuracy = tr_accuracy / nb_tr_steps\n","\n","    labels = [ids_to_labels[id.item()] for id in tr_labels]\n","    predictions = [ids_to_labels[id.item()] for id in tr_preds]\n","    f1 = seqeval.metrics.f1_score([labels], [predictions])\n","\n","    print(f\"Training loss epoch: {epoch_loss}\", f\"Training F1 epoch: {f1}\")\n","\n","def valid(model, test_loader, verbose=False):\n","    # put model in evaluation mode\n","    model.eval()\n","    \n","    eval_loss, eval_accuracy = 0, 0\n","    nb_eval_examples, nb_eval_steps = 0, 0\n","    eval_preds, eval_labels = [], []\n","    \n","    with torch.no_grad():\n","        for idx, batch in enumerate(test_loader):\n","            \n","            ids, labels = batch\n","            ids = ids.to(device)\n","            labels = labels.to(device)\n","            mask = ids!=1 \n","\n","            outputs = model(input_ids=ids, attention_mask=mask, labels=labels)\n","            loss = outputs[0]\n","            eval_logits = outputs[1]\n","            eval_loss += loss.item()\n","\n","            nb_eval_steps += 1\n","            nb_eval_examples += labels.size(0)\n","        \n","            if idx % 100==0 and verbose:\n","                loss_step = eval_loss/nb_eval_steps\n","                print(f\"Validation loss per 100 evaluation steps: {loss_step}\")\n","              \n","            # compute evaluation accuracy\n","            flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n","            active_logits = eval_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n","            flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n","            \n","            # only compute accuracy at active labels\n","            active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n","        \n","            labels = torch.masked_select(flattened_targets, active_accuracy)\n","            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n","            \n","            eval_labels.extend(labels)\n","            eval_preds.extend(predictions)\n","            \n","\n","    labels = [ids_to_labels[id.item()] for id in eval_labels]\n","    predictions = [ids_to_labels[id.item()] for id in eval_preds]\n","    \n","    eval_loss = eval_loss / nb_eval_steps\n","    eval_accuracy = eval_accuracy / nb_eval_steps\n","    f1 = seqeval.metrics.f1_score([labels], [predictions])\n","    print(f\"Validation Loss: {eval_loss}\", f\"Validation F1: {f1}\")\n","\n","    return labels, predictions, f1\n","\n","def train_crf(epoch, verbose = False):\n","    tr_loss, tr_accuracy = 0, 0\n","    nb_tr_examples, nb_tr_steps = 0, 0\n","    tr_preds, tr_labels = [], []\n","    model.train()\n","    \n","    for idx, batch in enumerate(train_loader):\n","        ids, labels = batch\n","        ids = ids.to(device)\n","        labels = labels.to(device)\n","        mask = ids!=1\n","        \n","        outputs = model(input_ids=ids, attention_mask=mask, labels=labels)\n","        loss = outputs[0]\n","                \n","        tr_loss += loss.item()\n","\n","        nb_tr_steps += 1\n","        nb_tr_examples += labels.size(0)\n","        \n","        if idx % 100==0 and verbose:\n","            loss_step = tr_loss/nb_tr_steps\n","            print(f\"Training loss per 100 training steps: {loss_step}\")\n","           \n","        flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n","        flattened_predictions = outputs[1].view(-1)\n","        \n","        # only compute accuracy at active labels\n","        active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n","        active_labels = torch.where(active_accuracy, labels.view(-1), torch.tensor(-100).type_as(labels))\n","        \n","        labels = torch.masked_select(flattened_targets, active_accuracy)\n","        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n","        \n","        tr_labels.extend(labels)\n","        tr_preds.extend(predictions)\n","    \n","        # gradient clipping\n","        torch.nn.utils.clip_grad_norm_(\n","            parameters=model.parameters(), max_norm=MAX_GRAD_NORM\n","        )\n","        \n","        # backward pass\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        try: \n","            scheduler0.step()\n","        except:\n","            scheduler.step()\n","            \n","    epoch_loss = tr_loss / nb_tr_steps\n","    tr_accuracy = tr_accuracy / nb_tr_steps\n","\n","    labels = [ids_to_labels[id.item()] for id in tr_labels]\n","    predictions = [ids_to_labels[id.item()] for id in tr_preds]\n","    f1 = seqeval.metrics.f1_score([labels], [predictions])\n","\n","    print(f\"Training loss epoch: {epoch_loss}\", f\"Training F1 epoch: {f1}\")\n","\n","def valid_crf(model, test_loader, verbose=False):\n","    # put model in evaluation mode\n","    model.eval()\n","    \n","    eval_loss, eval_accuracy = 0, 0\n","    nb_eval_examples, nb_eval_steps = 0, 0\n","    eval_preds, eval_labels = [], []\n","    \n","    with torch.no_grad():\n","        for idx, batch in enumerate(test_loader):\n","            \n","            ids, labels = batch\n","            ids = ids.to(device)\n","            labels = labels.to(device)\n","            mask = ids!=1 \n","\n","            outputs = model(input_ids=ids, attention_mask=mask, labels=labels)\n","            loss = outputs[0]\n","            eval_loss += loss.item()\n","\n","            nb_eval_steps += 1\n","            nb_eval_examples += labels.size(0)\n","        \n","            if idx % 100==0 and verbose:\n","                loss_step = eval_loss/nb_eval_steps\n","                print(f\"Validation loss per 100 evaluation steps: {loss_step}\")\n","              \n","            # compute evaluation accuracy\n","            flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n","            flattened_predictions = outputs[1].view(-1)\n","            \n","            # only compute accuracy at active labels\n","            active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n","            active_labels = torch.where(active_accuracy, labels.view(-1), torch.tensor(-100).type_as(labels))\n","\n","            labels = torch.masked_select(flattened_targets, active_accuracy)\n","            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n","            \n","            eval_labels.extend(labels)\n","            eval_preds.extend(predictions)\n","            \n","\n","    labels = [ids_to_labels[id.item()] for id in eval_labels]\n","    predictions = [ids_to_labels[id.item()] for id in eval_preds]\n","    \n","    eval_loss = eval_loss / nb_eval_steps\n","    # eval_accuracy = eval_accuracy / nb_eval_steps\n","    f1 = seqeval.metrics.f1_score([labels], [predictions])\n","    print(f\"Validation Loss: {eval_loss}\", f\"Validation F1: {f1}\")\n","\n","    return labels, predictions, f1"],"metadata":{"id":"J3Qxsp2gXq3P"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Default Phobert + Linear layer + Tiki dataset"],"metadata":{"id":"hTw8AYfHGszL"}},{"cell_type":"code","source":["class RobertaForTokenClassification(RobertaPreTrainedModel):\n","    _keys_to_ignore_on_load_unexpected = [r\"pooler\"]\n","    _keys_to_ignore_on_load_missing = [r\"position_ids\"]\n","\n","    def __init__(self, config, class_weight=None):\n","        super().__init__(config)\n","        self.num_labels = config.num_labels\n","        self.roberta = RobertaModel(config, add_pooling_layer=False)\n","        classifier_dropout = (\n","            config.classifier_dropout if config.classifier_dropout is not None else config.hidden_dropout_prob\n","        )\n","        self.dropout = nn.Dropout(classifier_dropout)\n","        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n","        # Initialize weights and apply final processing\n","        self.post_init()\n","\n","    def forward(\n","        self,\n","        input_ids=None,\n","        attention_mask=None,\n","        token_type_ids=None,\n","        position_ids=None,\n","        head_mask=None,\n","        inputs_embeds=None,\n","        labels=None,\n","        output_attentions=None,\n","        output_hidden_states=None,\n","        return_dict=None,\n","    ):\n","        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n","\n","        outputs = self.roberta(\n","            input_ids,\n","            attention_mask=attention_mask,\n","            token_type_ids=token_type_ids,\n","            position_ids=position_ids,\n","            head_mask=head_mask,\n","            inputs_embeds=inputs_embeds,\n","            output_attentions=output_attentions,\n","            output_hidden_states=output_hidden_states,\n","            return_dict=return_dict,\n","        )\n","\n","        sequence_output = outputs[0]\n","\n","        sequence_output = self.dropout(sequence_output)\n","        logits = self.classifier(sequence_output)\n","\n","        loss = None\n","        if labels is not None:\n","            if class_weight is not None:\n","                loss_fct = nn.CrossEntropyLoss(weight=torch.tensor(class_weight, dtype=torch.float).to(device))\n","            else: \n","                loss_fct = nn.CrossEntropyLoss()\n","            # Only keep active parts of the loss\n","            if attention_mask is not None:\n","                active_loss = attention_mask.view(-1) == 1\n","                active_logits = logits.view(-1, self.num_labels)\n","                active_labels = torch.where(\n","                    active_loss, labels.view(-1), torch.tensor(loss_fct.ignore_index).type_as(labels)\n","                )\n","                loss = loss_fct(active_logits, active_labels)\n","            else:\n","                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n","\n","        if not return_dict:\n","            output = (logits,) + outputs[2:]\n","            return ((loss,) + output) if loss is not None else output\n","\n","        return TokenClassifierOutput(\n","            loss=loss,\n","            logits=logits,\n","            hidden_states=outputs.hidden_states,\n","            attentions=outputs.attentions,\n","        )\n","\n","checkpoint_path = './checkpoints/RobertaForTokenClassification_best.pth'\n","model = RobertaForTokenClassification.from_pretrained(\"vinai/phobert-base\", config=config, class_weight=class_weight)\n","model.cuda()"],"metadata":{"id":"_g1hWIJDIezR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["param_optimizer = list(model.named_parameters())\n","no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n","optimizer_grouped_parameters = [\n","    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n","    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n","]\n","num_train_optimization_steps = int(args.epochs*len(train_dataset)/BATCHSIZE_TRAIN/args.accumulation_steps)\n","optimizer = AdamW(optimizer_grouped_parameters, lr=LEARNING_RATE, correct_bias=False)  # To reproduce BertAdam specific behavior set correct_bias=False\n","scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=100, num_training_steps=num_train_optimization_steps)  # PyTorch scheduler\n","# scheduler0 = get_constant_schedule(optimizer)  # PyTorch scheduler\n","\n","print(\"Learning rate: \", LEARNING_RATE)\n","print(\"num_train_optimization_steps:\", num_train_optimization_steps)\n","\n","tsfm = model.roberta\n","for child in tsfm.children():\n","    for param in child.parameters():\n","        if not param.requires_grad:\n","            print(\"whoopsies\")\n","        param.requires_grad = False\n","frozen = True"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qa1AGCV8QI32","executionInfo":{"status":"ok","timestamp":1640248598046,"user_tz":-420,"elapsed":21,"user":{"displayName":"Quang Duy Tran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghu2xyMtK_2iyS9Voe4qtTbv8PTTDqItODbJlD0Uw=s64","userId":"16933642894382662697"}},"outputId":"fee2c2d4-dd8c-4612-a71e-d5d20714b68d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Learning rate:  5e-05\n","num_train_optimization_steps: 7315\n"]}]},{"cell_type":"code","source":["f1_best = 0\n","for epoch in range(NUM_EPOCH):\n","    if epoch > 0 and frozen:\n","        for child in tsfm.children():\n","            for param in child.parameters():\n","                param.requires_grad = True\n","        frozen = False\n","        try:\n","            del scheduler0\n","        except:\n","            pass\n","        torch.cuda.empty_cache()\n","    st = time.time()\n","    print(f\"Training epoch: {epoch + 1}\")\n","    train(epoch)\n","    labels, predictions, f1_val = valid(model, valid_loader)\n","    if f1_val > f1_best:\n","        f1_best = f1_val\n","        print(f'New best f1 {f1_best}')\n","        print(classification_report([labels], [predictions]))\n","    # save best model\n","    torch.save(model.state_dict(), checkpoint_path)\n","    for param_group in optimizer.param_groups:\n","        print('Current leanring rate: ',param_group['lr'])\n","    print('Time: ',time.time() - st)\n","    print('======================================================')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jkqnn-a33hqI","executionInfo":{"status":"ok","timestamp":1640249697378,"user_tz":-420,"elapsed":1099336,"user":{"displayName":"Quang Duy Tran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghu2xyMtK_2iyS9Voe4qtTbv8PTTDqItODbJlD0Uw=s64","userId":"16933642894382662697"}},"outputId":"303bc61a-db87-4c0b-ee7d-13a8250b970f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss epoch: 1.3817361876612804 Training F1 epoch: 0.21314087090856426\n","Validation Loss: 1.1099360878350304 Validation F1: 0.3970752261742471\n","New best f1 0.3970752261742471\n","              precision    recall  f1-score   support\n","\n","         DES       0.31      0.66      0.42      2274\n","         PRI       0.13      0.53      0.21       182\n","\n","   micro avg       0.29      0.65      0.40      2456\n","   macro avg       0.22      0.59      0.32      2456\n","weighted avg       0.30      0.65      0.41      2456\n","\n","Current leanring rate:  4.815661815661816e-05\n","Current leanring rate:  4.815661815661816e-05\n","Time:  23.66596531867981\n","======================================================\n","Training epoch: 2\n","Training loss epoch: 0.4276883712068933 Training F1 epoch: 0.6334981724360352\n","Validation Loss: 0.27126219238617705 Validation F1: 0.732488822652757\n","New best f1 0.732488822652757\n","              precision    recall  f1-score   support\n","\n","         DES       0.70      0.80      0.75      2274\n","         PRI       0.44      0.75      0.55       182\n","\n","   micro avg       0.68      0.80      0.73      2456\n","   macro avg       0.57      0.78      0.65      2456\n","weighted avg       0.68      0.80      0.74      2456\n","\n","Current leanring rate:  4.562023562023562e-05\n","Current leanring rate:  4.562023562023562e-05\n","Time:  56.808470249176025\n","======================================================\n","Training epoch: 3\n","Training loss epoch: 0.18770277165283597 Training F1 epoch: 0.813009690108414\n","Validation Loss: 0.20891093207228054 Validation F1: 0.8368380062305296\n","New best f1 0.8368380062305296\n","              precision    recall  f1-score   support\n","\n","         DES       0.82      0.88      0.85      2274\n","         PRI       0.65      0.84      0.73       182\n","\n","   micro avg       0.80      0.88      0.84      2456\n","   macro avg       0.73      0.86      0.79      2456\n","weighted avg       0.80      0.88      0.84      2456\n","\n","Current leanring rate:  4.3083853083853084e-05\n","Current leanring rate:  4.3083853083853084e-05\n","Time:  56.85277581214905\n","======================================================\n","Training epoch: 4\n","Training loss epoch: 0.11822718419287293 Training F1 epoch: 0.8617838157117542\n","Validation Loss: 0.20700470151003103 Validation F1: 0.8698213233850384\n","New best f1 0.8698213233850384\n","              precision    recall  f1-score   support\n","\n","         DES       0.85      0.90      0.88      2274\n","         PRI       0.70      0.88      0.78       182\n","\n","   micro avg       0.84      0.90      0.87      2456\n","   macro avg       0.78      0.89      0.83      2456\n","weighted avg       0.84      0.90      0.87      2456\n","\n","Current leanring rate:  4.054747054747055e-05\n","Current leanring rate:  4.054747054747055e-05\n","Time:  56.720470666885376\n","======================================================\n","Training epoch: 5\n","Training loss epoch: 0.08835865198405551 Training F1 epoch: 0.8909298515613364\n","Validation Loss: 0.23059696161132204 Validation F1: 0.8580781821683034\n","Current leanring rate:  3.8011088011088013e-05\n","Current leanring rate:  3.8011088011088013e-05\n","Time:  56.38459229469299\n","======================================================\n","Training epoch: 6\n","Training loss epoch: 0.07689864842394173 Training F1 epoch: 0.9018145662440964\n","Validation Loss: 0.22403271553549367 Validation F1: 0.8934089575591628\n","New best f1 0.8934089575591628\n","              precision    recall  f1-score   support\n","\n","         DES       0.88      0.93      0.90      2274\n","         PRI       0.67      0.92      0.78       182\n","\n","   micro avg       0.86      0.93      0.89      2456\n","   macro avg       0.78      0.92      0.84      2456\n","weighted avg       0.86      0.93      0.89      2456\n","\n","Current leanring rate:  3.5474705474705475e-05\n","Current leanring rate:  3.5474705474705475e-05\n","Time:  56.38813829421997\n","======================================================\n","Training epoch: 7\n","Training loss epoch: 0.04599723350791047 Training F1 epoch: 0.9340340340340341\n","Validation Loss: 0.22076550562728625 Validation F1: 0.879506074487154\n","Current leanring rate:  3.293832293832294e-05\n","Current leanring rate:  3.293832293832294e-05\n","Time:  56.26538014411926\n","======================================================\n","Training epoch: 8\n","Training loss epoch: 0.03864376417417181 Training F1 epoch: 0.9440594556593351\n","Validation Loss: 0.2157734966126927 Validation F1: 0.8549820381924749\n","Current leanring rate:  3.0401940401940404e-05\n","Current leanring rate:  3.0401940401940404e-05\n","Time:  56.159600257873535\n","======================================================\n","Training epoch: 9\n","Training loss epoch: 0.03318289001828538 Training F1 epoch: 0.9499749373433585\n","Validation Loss: 0.25902186675999783 Validation F1: 0.8827342368886271\n","Current leanring rate:  2.7865557865557868e-05\n","Current leanring rate:  2.7865557865557868e-05\n","Time:  56.53106093406677\n","======================================================\n","Training epoch: 10\n","Training loss epoch: 0.02590558307863711 Training F1 epoch: 0.9545202719717956\n","Validation Loss: 0.26003926131006616 Validation F1: 0.9050345508390918\n","New best f1 0.9050345508390918\n","              precision    recall  f1-score   support\n","\n","         DES       0.88      0.94      0.91      2274\n","         PRI       0.82      0.88      0.85       182\n","\n","   micro avg       0.88      0.93      0.91      2456\n","   macro avg       0.85      0.91      0.88      2456\n","weighted avg       0.88      0.93      0.91      2456\n","\n","Current leanring rate:  2.532917532917533e-05\n","Current leanring rate:  2.532917532917533e-05\n","Time:  56.69581890106201\n","======================================================\n","Training epoch: 11\n","Training loss epoch: 0.020352689429730828 Training F1 epoch: 0.9608870967741936\n","Validation Loss: 0.27327362962812696 Validation F1: 0.9044585987261146\n","Current leanring rate:  2.2792792792792794e-05\n","Current leanring rate:  2.2792792792792794e-05\n","Time:  56.686272621154785\n","======================================================\n","Training epoch: 12\n","Training loss epoch: 0.017076628541260897 Training F1 epoch: 0.9670972951150586\n","Validation Loss: 0.28248094677889485 Validation F1: 0.9088364654138344\n","New best f1 0.9088364654138344\n","              precision    recall  f1-score   support\n","\n","         DES       0.90      0.93      0.91      2274\n","         PRI       0.82      0.91      0.86       182\n","\n","   micro avg       0.89      0.93      0.91      2456\n","   macro avg       0.86      0.92      0.89      2456\n","weighted avg       0.89      0.93      0.91      2456\n","\n","Current leanring rate:  2.025641025641026e-05\n","Current leanring rate:  2.025641025641026e-05\n","Time:  56.72002196311951\n","======================================================\n","Training epoch: 13\n","Training loss epoch: 0.018714859723202536 Training F1 epoch: 0.9645669291338581\n","Validation Loss: 0.2887308362354855 Validation F1: 0.9158653846153846\n","New best f1 0.9158653846153846\n","              precision    recall  f1-score   support\n","\n","         DES       0.90      0.93      0.92      2274\n","         PRI       0.87      0.92      0.89       182\n","\n","   micro avg       0.90      0.93      0.92      2456\n","   macro avg       0.89      0.92      0.91      2456\n","weighted avg       0.90      0.93      0.92      2456\n","\n","Current leanring rate:  1.772002772002772e-05\n","Current leanring rate:  1.772002772002772e-05\n","Time:  56.83630561828613\n","======================================================\n","Training epoch: 14\n","Training loss epoch: 0.018226241715165882 Training F1 epoch: 0.961965532834246\n","Validation Loss: 0.27599319967802594 Validation F1: 0.9142743221690591\n","Current leanring rate:  1.5183645183645184e-05\n","Current leanring rate:  1.5183645183645184e-05\n","Time:  56.49777293205261\n","======================================================\n","Training epoch: 15\n","Training loss epoch: 0.014331742942389203 Training F1 epoch: 0.9676019378280177\n","Validation Loss: 0.27758984648701457 Validation F1: 0.9137760158572844\n","Current leanring rate:  1.2647262647262647e-05\n","Current leanring rate:  1.2647262647262647e-05\n","Time:  56.493226528167725\n","======================================================\n","Training epoch: 16\n","Training loss epoch: 0.011631878854991878 Training F1 epoch: 0.973139764277404\n","Validation Loss: 0.28893278276451095 Validation F1: 0.9181836367273454\n","New best f1 0.9181836367273454\n","              precision    recall  f1-score   support\n","\n","         DES       0.91      0.94      0.92      2274\n","         PRI       0.84      0.91      0.87       182\n","\n","   micro avg       0.90      0.93      0.92      2456\n","   macro avg       0.87      0.92      0.90      2456\n","weighted avg       0.90      0.93      0.92      2456\n","\n","Current leanring rate:  1.0110880110880111e-05\n","Current leanring rate:  1.0110880110880111e-05\n","Time:  56.73111343383789\n","======================================================\n","Training epoch: 17\n","Training loss epoch: 0.009254867593628034 Training F1 epoch: 0.9794778014832877\n","Validation Loss: 0.30083362522275475 Validation F1: 0.9175340272217775\n","Current leanring rate:  7.574497574497574e-06\n","Current leanring rate:  7.574497574497574e-06\n","Time:  56.735159158706665\n","======================================================\n","Training epoch: 18\n","Training loss epoch: 0.008299988879608448 Training F1 epoch: 0.9816150330116812\n","Validation Loss: 0.30710122909090265 Validation F1: 0.916916916916917\n","Current leanring rate:  5.038115038115039e-06\n","Current leanring rate:  5.038115038115039e-06\n","Time:  56.53474020957947\n","======================================================\n","Training epoch: 19\n","Training loss epoch: 0.006893407837793109 Training F1 epoch: 0.98388162912493\n","Validation Loss: 0.31450471894871546 Validation F1: 0.9182364729458918\n","New best f1 0.9182364729458918\n","              precision    recall  f1-score   support\n","\n","         DES       0.91      0.94      0.92      2274\n","         PRI       0.86      0.90      0.88       182\n","\n","   micro avg       0.90      0.93      0.92      2456\n","   macro avg       0.88      0.92      0.90      2456\n","weighted avg       0.90      0.93      0.92      2456\n","\n","Current leanring rate:  2.5017325017325016e-06\n","Current leanring rate:  2.5017325017325016e-06\n","Time:  57.01163840293884\n","======================================================\n","Training epoch: 20\n","Training loss epoch: 0.006449651978197482 Training F1 epoch: 0.9847860377550502\n","Validation Loss: 0.31522114748768815 Validation F1: 0.9180524944900822\n","Current leanring rate:  0.0\n","Current leanring rate:  0.0\n","Time:  56.64964818954468\n","======================================================\n"]}]},{"cell_type":"markdown","source":["## Phobert + LSTM + Linear + Tiki dataset"],"metadata":{"id":"87NrC-3SG1pb"}},{"cell_type":"code","source":["class RobertaLSTM(RobertaPreTrainedModel):\n","    _keys_to_ignore_on_load_unexpected = [r\"pooler\"]\n","    _keys_to_ignore_on_load_missing = [r\"position_ids\"]\n","\n","    def __init__(self, config, class_weight=None):\n","        super().__init__(config)\n","        self.num_labels = config.num_labels\n","\n","        self.roberta = RobertaModel(config, add_pooling_layer=False)\n","        classifier_dropout = (\n","            config.classifier_dropout if config.classifier_dropout is not None else config.hidden_dropout_prob\n","        )\n","        self.dropout = nn.Dropout(classifier_dropout)\n","        self.bilstm = nn.LSTM(config.hidden_size, (config.hidden_size) // 2, dropout=0.1, batch_first=True, bidirectional=True)\n","        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n","\n","        # Initialize weights and apply final processing\n","        self.post_init()\n","\n","\n","    def forward(\n","        self,\n","        input_ids=None,\n","        attention_mask=None,\n","        token_type_ids=None,\n","        position_ids=None,\n","        head_mask=None,\n","        inputs_embeds=None,\n","        labels=None,\n","        output_attentions=None,\n","        output_hidden_states=None,\n","        return_dict=None,\n","    ):\n","        r\"\"\"\n","        labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size, sequence_length)`, `optional`):\n","            Labels for computing the token classification loss. Indices should be in ``[0, ..., config.num_labels -\n","            1]``.\n","        \"\"\"\n","        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n","\n","        outputs = self.roberta(\n","            input_ids,\n","            attention_mask=attention_mask,\n","            token_type_ids=token_type_ids,\n","            position_ids=position_ids,\n","            head_mask=head_mask,\n","            inputs_embeds=inputs_embeds,\n","            output_attentions=output_attentions,\n","            output_hidden_states=output_hidden_states,\n","            return_dict=return_dict,\n","        )\n","\n","        sequence_output = outputs[0]\n","\n","        sequence_output = self.dropout(sequence_output)\n","        lstm_output, hc = self.bilstm(sequence_output)\n","        logits = self.classifier(lstm_output)\n","\n","        loss = None\n","        if labels is not None:\n","            if class_weight is not None:\n","                loss_fct = nn.CrossEntropyLoss(weight=torch.tensor(class_weight, dtype=torch.float).to(device))\n","            else: \n","                loss_fct = nn.CrossEntropyLoss()\n","            # Only keep active parts of the loss\n","            if attention_mask is not None:\n","                active_loss = attention_mask.view(-1) == 1\n","                active_logits = logits.view(-1, self.num_labels)\n","                active_labels = torch.where(\n","                    active_loss, labels.view(-1), torch.tensor(loss_fct.ignore_index).type_as(labels)\n","                )\n","                loss = loss_fct(active_logits, active_labels)\n","            else:\n","                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n","\n","        if not return_dict:\n","            output = (logits,) + outputs[2:]\n","            return ((loss,) + output) if loss is not None else output\n","\n","        return TokenClassifierOutput(\n","            loss=loss,\n","            logits=logits,\n","            hidden_states=outputs.hidden_states,\n","            attentions=outputs.attentions,\n","        )"],"metadata":{"id":"a6YCktfxG8Ii"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class_weight"],"metadata":{"id":"PH9zfI31TIy7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = RobertaLSTM.from_pretrained('vinai/phobert-base', num_labels=5, class_weight=class_weight)\n","model.to(device)"],"metadata":{"id":"6hvUZSc5OWM9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Creating optimizer and lr schedulers\n","param_optimizer = list(model.named_parameters())\n","no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n","optimizer_grouped_parameters = [\n","    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n","    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n","]\n","num_train_optimization_steps = int(args.epochs*len(train_dataset)/BATCHSIZE_TRAIN/args.accumulation_steps)\n","optimizer = AdamW(optimizer_grouped_parameters, lr=LEARNING_RATE, correct_bias=False)  # To reproduce BertAdam specific behavior set correct_bias=False\n","scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=100, num_training_steps=num_train_optimization_steps)  # PyTorch scheduler\n","scheduler0 = get_constant_schedule(optimizer)  # PyTorch scheduler\n"],"metadata":{"id":"O98Xwy0KQ-o1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tsfm = model.roberta\n","for child in tsfm.children():\n","    for param in child.parameters():\n","        if not param.requires_grad:\n","            print(\"whoopsies\")\n","        param.requires_grad = False\n","frozen = True"],"metadata":{"id":"PoljO15xQ-o3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["EPOCHS = 10\n","MAX_GRAD_NORM = 1\n","\"\"\"\n","Although LSTMs tend to not suffer from the vanishing gradient problem, they can have exploding gradients. Thus we enforced a hard constraint on the norm of the gradient [10,25] by scaling it when its norm exceeded a threshold. …\"\"\"\n","# It usually improves the training (and is pretty much always done in the fine-tuning scripts of research papers)\n","import time\n","\n","for epoch in range(EPOCHS):\n","    if epoch > 0 and frozen:\n","        for child in tsfm.children():\n","            for param in child.parameters():\n","                param.requires_grad = True\n","        frozen = False\n","        del scheduler0\n","        torch.cuda.empty_cache()\n","    st = time.time()\n","    print(f\"Training epoch: {epoch + 1}\")\n","    train(epoch)\n","    labels, predictions = valid(model, valid_loader)\n","    \n","    print('Time: ',time.time() - st)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1640072003150,"user_tz":-420,"elapsed":861820,"user":{"displayName":"Quang Duy Tran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghu2xyMtK_2iyS9Voe4qtTbv8PTTDqItODbJlD0Uw=s64","userId":"16933642894382662697"}},"outputId":"64af6585-fccb-4ed1-b6f3-c5d8e52d70a9","id":"BA_QhddXQ-o4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss epoch: 0.6089032675480582 Training F1 epoch: 0.43946262259952196\n","Validation Loss: 0.35876590766704797 Validation F1: 0.5721812434141201\n","Time:  39.062042236328125\n","Training epoch: 2\n","Training loss epoch: 0.3594023005812953 Training F1 epoch: 0.6321728361084354\n","Validation Loss: 0.16580462273047433 Validation F1: 0.8174217382850476\n","Time:  91.36617231369019\n","Training epoch: 3\n","Training loss epoch: 0.156797271983983 Training F1 epoch: 0.8203178991015895\n","Validation Loss: 0.1470461653162537 Validation F1: 0.8620826709062003\n","Time:  91.00090837478638\n","Training epoch: 4\n","Training loss epoch: 0.09983247618605713 Training F1 epoch: 0.8787376250062817\n","Validation Loss: 0.157449078767451 Validation F1: 0.874526231797327\n","Time:  91.34242296218872\n","Training epoch: 5\n","Training loss epoch: 0.07098762261079461 Training F1 epoch: 0.8970254027574366\n","Validation Loss: 0.16526996120530604 Validation F1: 0.9080530071355759\n","Time:  91.20107316970825\n","Training epoch: 6\n","Training loss epoch: 0.05678709343017226 Training F1 epoch: 0.9142857142857143\n","Validation Loss: 0.16349965903101377 Validation F1: 0.8848730964467005\n","Time:  90.99708700180054\n","Training epoch: 7\n","Training loss epoch: 0.10381579785808143 Training F1 epoch: 0.8627373417721519\n","Validation Loss: 0.18471190943688032 Validation F1: 0.8202402047647174\n","Time:  91.57931756973267\n","Training epoch: 8\n","Training loss epoch: 0.0784907435458866 Training F1 epoch: 0.8996620087776824\n","Validation Loss: 0.15923820158448884 Validation F1: 0.8832507433102081\n","Time:  91.46027541160583\n","Training epoch: 9\n","Training loss epoch: 0.043026268168745684 Training F1 epoch: 0.936793893129771\n","Validation Loss: 0.17005037491084485 Validation F1: 0.8857771554310863\n","Time:  91.62588286399841\n","Training epoch: 10\n","Training loss epoch: 0.03823844363239894 Training F1 epoch: 0.9364643692182576\n","Validation Loss: 0.1768970886071065 Validation F1: 0.9072701782495494\n","Time:  92.03645658493042\n"]}]},{"cell_type":"markdown","source":["## Phobert + CRF + Tiki dataset"],"metadata":{"id":"FLfiCckAHPWB"}},{"cell_type":"code","source":["class RobertaCRF(RobertaPreTrainedModel):\n","\n","    _keys_to_ignore_on_load_unexpected = [r\"pooler\"]\n","    _keys_to_ignore_on_load_missing = [r\"position_ids\"]\n","\n","    def __init__(self, config):\n","        super().__init__(config)\n","        self.num_labels = config.num_labels\n","\n","        self.roberta = RobertaModel(config, add_pooling_layer=False)\n","        classifier_dropout = (\n","            config.classifier_dropout if config.classifier_dropout is not None else config.hidden_dropout_prob\n","        )\n","        self.dropout = nn.Dropout(classifier_dropout)\n","        self.classifier = nn.Linear(config.hidden_size, self.num_labels)\n","\n","        self.crf = CRF(num_tags=self.num_labels, batch_first=True)\n","        # self.post_init()\n","        self.init_weights()\n","\n","    def forward(\n","        self,\n","        input_ids=None,\n","        attention_mask=None,\n","        token_type_ids=None,\n","        position_ids=None,\n","        head_mask=None,\n","        inputs_embeds=None,\n","        labels=None,\n","        output_attentions=None,\n","        output_hidden_states=None,\n","        return_dict=None,\n","    ):\n","        r\"\"\"\n","        labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size, sequence_length)`, `optional`):\n","            Labels for computing the token classification loss. Indices should be in ``[0, ..., config.num_labels -\n","            1]``.\n","        \"\"\"\n","        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n","\n","        outputs = self.roberta(\n","            input_ids,\n","            attention_mask=attention_mask,\n","            token_type_ids=token_type_ids,\n","            position_ids=position_ids,\n","            head_mask=head_mask,\n","            inputs_embeds=inputs_embeds,\n","            output_attentions=output_attentions,\n","            output_hidden_states=output_hidden_states,\n","            return_dict=return_dict,\n","        )\n","\n","        sequence_output = outputs[0]\n","        sequence_output = self.dropout(sequence_output)\n","        logits = self.classifier(sequence_output)\n","\n","        loss = None\n","        if labels is not None:\n","            labels_copy = torch.clone(labels)\n","            labels_copy[labels==-100] = 0\n","            log_likelihood, tags = self.crf(logits, labels_copy), self.crf.decode(logits)\n","            loss = 0 - log_likelihood\n","        else:\n","            tags = self.crf.decode(logits)\n","        tags = torch.Tensor(tags)\n","        tags = tags.to(device)\n","\n","        if not return_dict:\n","            output = (tags,) + outputs[2:]\n","            return ((loss,) + output) if loss is not None else output\n","\n","        return loss, tags"],"metadata":{"id":"HFmwsDfeHUJZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = RobertaCRF.from_pretrained('vinai/phobert-base', num_labels=5)\n","model.cuda()"],"metadata":{"id":"Os7ldVmd5P_c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Creating optimizer and lr schedulers\n","param_optimizer = list(model.named_parameters())\n","no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n","optimizer_grouped_parameters = [\n","    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n","    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n","]\n","num_train_optimization_steps = int(args.epochs*len(train_dataset)/args.batch_size/args.accumulation_steps)\n","optimizer = AdamW(optimizer_grouped_parameters, lr=5e-5, correct_bias=False)  # To reproduce BertAdam specific behavior set correct_bias=False\n","scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=100, num_training_steps=num_train_optimization_steps)  # PyTorch scheduler\n","scheduler0 = get_constant_schedule(optimizer)  # PyTorch scheduler\n","\n","tsfm = model.roberta\n","for child in tsfm.children():\n","    for param in child.parameters():\n","        if not param.requires_grad:\n","            print(\"whoopsies\")\n","        param.requires_grad = False\n","frozen = True\n","\n","EPOCHS = 10\n","MAX_GRAD_NORM = 10\n","\n","import time\n","\n","for epoch in range(EPOCHS):\n","    if epoch > 0 and frozen:\n","        for child in tsfm.children():\n","            for param in child.parameters():\n","                param.requires_grad = True\n","        frozen = False\n","        del scheduler0\n","        torch.cuda.empty_cache()\n","    st = time.time()\n","    print(f\"Training epoch: {epoch + 1}\")\n","    train_modified(epoch)\n","    labels, predictions = valid_modified(model, valid_loader)\n","    \n","    print('Time: ',time.time() - st)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BhSDwHo98xua","executionInfo":{"status":"ok","timestamp":1640100663683,"user_tz":-420,"elapsed":4056234,"user":{"displayName":"Quang Duy Tran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghu2xyMtK_2iyS9Voe4qtTbv8PTTDqItODbJlD0Uw=s64","userId":"16933642894382662697"}},"outputId":"e6badaa3-1382-481c-dbdb-781889be7a39"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torchcrf/__init__.py:249: UserWarning: where received a uint8 condition tensor. This behavior is deprecated and will be removed in a future version of PyTorch. Use a boolean condition instead. (Triggered internally at  ../aten/src/ATen/native/TensorCompare.cpp:328.)\n","  score = torch.where(mask[i].unsqueeze(1), next_score, score)\n"]},{"output_type":"stream","name":"stdout","text":["Training loss epoch: 141.1873681949136 Training F1 epoch: 0.010669715156711442\n","Validation Loss: 30.532176116776597 Validation F1: 0.0016253555465258025\n","Time:  341.531724691391\n","Training epoch: 2\n","Training loss epoch: 16.23040179476712 Training F1 epoch: 0.7982217573221758\n","Validation Loss: 4.768356740148993 Validation F1: 0.8821261919253398\n","Time:  412.92261958122253\n","Training epoch: 3\n","Training loss epoch: 6.580289830275572 Training F1 epoch: 0.9179917626818206\n","Validation Loss: 3.6424914083845628 Validation F1: 0.925264012997563\n","Time:  411.90776658058167\n","Training epoch: 4\n","Training loss epoch: 4.381463306197703 Training F1 epoch: 0.9429851990827601\n","Validation Loss: 3.985554846258111 Validation F1: 0.915184958103413\n","Time:  412.2711532115936\n","Training epoch: 5\n","Training loss epoch: 3.25973218907424 Training F1 epoch: 0.9550573514077164\n","Validation Loss: 3.832001232710041 Validation F1: 0.9256097560975609\n","Time:  412.1608827114105\n","Training epoch: 6\n","Training loss epoch: 3.1167723442035946 Training F1 epoch: 0.9574689878036068\n","Validation Loss: 4.960251938449881 Validation F1: 0.9129116993331987\n","Time:  412.02876687049866\n","Training epoch: 7\n","Training loss epoch: 2.1713440274931695 Training F1 epoch: 0.9666077187142412\n","Validation Loss: 4.823043072809939 Validation F1: 0.9199679871948779\n","Time:  412.3896486759186\n","Training epoch: 8\n","Training loss epoch: 2.553066566342213 Training F1 epoch: 0.962766234442535\n","Validation Loss: 4.004213593696636 Validation F1: 0.9243697478991597\n","Time:  412.5732305049896\n","Training epoch: 9\n","Training loss epoch: 1.9120571782680158 Training F1 epoch: 0.9735499323128189\n","Validation Loss: 4.414583299980789 Validation F1: 0.9320701471477526\n","Time:  414.12650537490845\n","Training epoch: 10\n","Training loss epoch: 1.3469604325424778 Training F1 epoch: 0.9777870259584872\n","Validation Loss: 4.554044462943989 Validation F1: 0.9375513557929335\n","Time:  414.1243920326233\n"]}]},{"cell_type":"markdown","source":["## Phobert + LSTM + CRF + Tiki dataset"],"metadata":{"id":"Y5i4fuQrHUne"}},{"cell_type":"markdown","source":["https://github.com/hemingkx/CLUENER2020/tree/main/BERT-Softmax"],"metadata":{"id":"-YkZxXqfF2vY"}},{"cell_type":"code","source":["class RobertaLSTMCRF(RobertaPreTrainedModel):\n","\n","    _keys_to_ignore_on_load_unexpected = [r\"pooler\"]\n","    _keys_to_ignore_on_load_missing = [r\"position_ids\"]\n","\n","    def __init__(self, config):\n","        super().__init__(config)\n","        self.num_labels = config.num_labels\n","\n","        self.roberta = RobertaModel(config, add_pooling_layer=False)\n","        classifier_dropout = (\n","            config.classifier_dropout if config.classifier_dropout is not None else config.hidden_dropout_prob\n","        )\n","        self.dropout = nn.Dropout(classifier_dropout)\n","        self.bilstm = nn.LSTM(config.hidden_size, (config.hidden_size) // 2, dropout=0.5, batch_first=True, bidirectional=True)\n","        self.classifier = nn.Linear(config.hidden_size, self.num_labels)\n","\n","        self.crf = CRF(num_tags=self.num_labels, batch_first=True)\n","        self.post_init()\n","\n","    def forward(\n","        self,\n","        input_ids=None,\n","        attention_mask=None,\n","        token_type_ids=None,\n","        position_ids=None,\n","        head_mask=None,\n","        inputs_embeds=None,\n","        labels=None,\n","        output_attentions=None,\n","        output_hidden_states=None,\n","        return_dict=None,\n","    ):\n","        r\"\"\"\n","        labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size, sequence_length)`, `optional`):\n","            Labels for computing the token classification loss. Indices should be in ``[0, ..., config.num_labels -\n","            1]``.\n","        \"\"\"\n","        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n","\n","        outputs = self.roberta(\n","            input_ids,\n","            attention_mask=attention_mask,\n","            token_type_ids=token_type_ids,\n","            position_ids=position_ids,\n","            head_mask=head_mask,\n","            inputs_embeds=inputs_embeds,\n","            output_attentions=output_attentions,\n","            output_hidden_states=output_hidden_states,\n","            return_dict=return_dict,\n","        )\n","\n","        sequence_output = outputs[0]\n","        sequence_output = self.dropout(sequence_output)\n","        lstm_output, hc = self.bilstm(sequence_output)\n","        logits = self.classifier(lstm_output)\n","\n","        loss = None\n","        if labels is not None:\n","            labels[labels==-100] = 0\n","            log_likelihood, tags = self.crf(logits, labels), self.crf.decode(logits)\n","            loss = 0 - log_likelihood\n","        else:\n","            tags = self.crf.decode(logits)\n","        tags = torch.Tensor(tags)\n","        tags = tags.to(device)\n","\n","        if not return_dict:\n","            output = (tags,) + outputs[2:]\n","            return ((loss,) + output) if loss is not None else output\n","\n","        return loss, tags\n","\n","checkpoint_path = './checkpoints/RobertaLSTMCRF.pth'\n","model = RobertaLSTMCRF.from_pretrained('vinai/phobert-base', config=config)\n","model.cuda()"],"metadata":{"id":"U4AjvocHHY12","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1640251056276,"user_tz":-420,"elapsed":3208,"user":{"displayName":"Quang Duy Tran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghu2xyMtK_2iyS9Voe4qtTbv8PTTDqItODbJlD0Uw=s64","userId":"16933642894382662697"}},"outputId":"3d31a473-f807-4533-d23a-0360c0bf7bdb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n","  \"num_layers={}\".format(dropout, num_layers))\n","Some weights of the model checkpoint at vinai/phobert-base were not used when initializing RobertaLSTMCRF: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaLSTMCRF from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaLSTMCRF from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaLSTMCRF were not initialized from the model checkpoint at vinai/phobert-base and are newly initialized: ['crf.transitions', 'bilstm.bias_ih_l0_reverse', 'classifier.bias', 'crf.start_transitions', 'bilstm.bias_hh_l0_reverse', 'bilstm.bias_ih_l0', 'bilstm.weight_hh_l0', 'bilstm.weight_ih_l0_reverse', 'bilstm.weight_hh_l0_reverse', 'bilstm.weight_ih_l0', 'bilstm.bias_hh_l0', 'crf.end_transitions', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["RobertaLSTMCRF(\n","  (roberta): RobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(64001, 768, padding_idx=1)\n","      (position_embeddings): Embedding(258, 768, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): RobertaEncoder(\n","      (layer): ModuleList(\n","        (0): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (dropout): Dropout(p=0.5, inplace=False)\n","  (bilstm): LSTM(768, 384, batch_first=True, dropout=0.5, bidirectional=True)\n","  (classifier): Linear(in_features=768, out_features=5, bias=True)\n","  (crf): CRF(num_tags=5)\n",")"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["param_optimizer = list(model.named_parameters())\n","no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n","optimizer_grouped_parameters = [\n","    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n","    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n","]\n","num_train_optimization_steps = int(args.epochs*len(train_dataset)/BATCHSIZE_TRAIN/args.accumulation_steps)\n","optimizer = AdamW(optimizer_grouped_parameters, lr=LEARNING_RATE, correct_bias=False)  # To reproduce BertAdam specific behavior set correct_bias=False\n","scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=100, num_training_steps=num_train_optimization_steps)  # PyTorch scheduler\n","# scheduler0 = get_constant_schedule(optimizer)  # PyTorch scheduler\n","\n","print(\"Learning rate: \", LEARNING_RATE)\n","print(\"num_train_optimization_steps:\", num_train_optimization_steps)\n","\n","tsfm = model.roberta\n","for child in tsfm.children():\n","    for param in child.parameters():\n","        if not param.requires_grad:\n","            print(\"whoopsies\")\n","        param.requires_grad = False\n","frozen = True"],"metadata":{"id":"Ygafo_w0WzoM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1640251056277,"user_tz":-420,"elapsed":19,"user":{"displayName":"Quang Duy Tran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghu2xyMtK_2iyS9Voe4qtTbv8PTTDqItODbJlD0Uw=s64","userId":"16933642894382662697"}},"outputId":"aac6c91a-fa1e-41f4-b36c-b01051bb44d5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Learning rate:  5e-05\n","num_train_optimization_steps: 7315\n"]}]},{"cell_type":"code","source":["f1_best = 0\n","for epoch in range(NUM_EPOCH):\n","    if epoch > 0 and frozen:\n","        for child in tsfm.children():\n","            for param in child.parameters():\n","                param.requires_grad = True\n","        frozen = False\n","        try:\n","            del scheduler0\n","        except:\n","            pass\n","        torch.cuda.empty_cache()\n","    st = time.time()\n","    print(f\"Training epoch: {epoch + 1}\")\n","    train_crf(epoch)\n","    labels, predictions, f1_val = valid_crf(model, valid_loader)\n","    if f1_val > f1_best:\n","        f1_best = f1_val\n","        print(f'New best f1 {f1_best}')\n","        print(classification_report([labels], [predictions]))\n","    # save best model\n","    torch.save(model.state_dict(), checkpoint_path)\n","    for param_group in optimizer.param_groups:\n","        print('Current leanring rate: ',param_group['lr'])\n","    print('Time: ',time.time() - st)\n","    print('======================================================')"],"metadata":{"id":"1tl_ObVfpWv4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1640253553904,"user_tz":-420,"elapsed":2497634,"user":{"displayName":"Quang Duy Tran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghu2xyMtK_2iyS9Voe4qtTbv8PTTDqItODbJlD0Uw=s64","userId":"16933642894382662697"}},"outputId":"0388a058-30ac-4421-f0b6-85c55ec377cb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss epoch: 203.42970838703093 Training F1 epoch: 0.06472942404732905\n","Validation Loss: 37.71274921021175 Validation F1: 0.4856804733727811\n","New best f1 0.4856804733727811\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","         DES       0.58      0.45      0.51      2276\n","         PRI       0.00      0.00      0.00       182\n","\n","   micro avg       0.58      0.42      0.49      2458\n","   macro avg       0.29      0.23      0.25      2458\n","weighted avg       0.54      0.42      0.47      2458\n","\n","Current leanring rate:  4.815661815661816e-05\n","Current leanring rate:  4.815661815661816e-05\n","Time:  92.46463394165039\n","======================================================\n","Training epoch: 2\n","Training loss epoch: 33.295401734732536 Training F1 epoch: 0.7569843878389483\n","Validation Loss: 10.109715863003757 Validation F1: 0.8772993733575905\n","New best f1 0.8772993733575905\n","              precision    recall  f1-score   support\n","\n","         DES       0.89      0.89      0.89      2276\n","         PRI       0.67      0.74      0.70       182\n","\n","   micro avg       0.87      0.88      0.88      2458\n","   macro avg       0.78      0.82      0.80      2458\n","weighted avg       0.87      0.88      0.88      2458\n","\n","Current leanring rate:  4.562023562023562e-05\n","Current leanring rate:  4.562023562023562e-05\n","Time:  127.67286729812622\n","======================================================\n","Training epoch: 3\n","Training loss epoch: 15.512379964192709 Training F1 epoch: 0.9022386527007599\n","Validation Loss: 8.998190624466359 Validation F1: 0.9046554177678389\n","New best f1 0.9046554177678389\n","              precision    recall  f1-score   support\n","\n","         DES       0.91      0.91      0.91      2276\n","         PRI       0.83      0.86      0.84       182\n","\n","   micro avg       0.90      0.91      0.90      2458\n","   macro avg       0.87      0.88      0.88      2458\n","weighted avg       0.90      0.91      0.90      2458\n","\n","Current leanring rate:  4.3083853083853084e-05\n","Current leanring rate:  4.3083853083853084e-05\n","Time:  127.04852294921875\n","======================================================\n","Training epoch: 4\n","Training loss epoch: 11.121844849299864 Training F1 epoch: 0.9331690791499845\n","Validation Loss: 9.620251931779372 Validation F1: 0.9009405643386033\n","Current leanring rate:  4.054747054747055e-05\n","Current leanring rate:  4.054747054747055e-05\n","Time:  126.30352473258972\n","======================================================\n","Training epoch: 5\n","Training loss epoch: 8.19253840211962 Training F1 epoch: 0.9505918682449821\n","Validation Loss: 11.193711244343408 Validation F1: 0.9124177631578947\n","New best f1 0.9124177631578947\n","              precision    recall  f1-score   support\n","\n","         DES       0.93      0.91      0.92      2276\n","         PRI       0.84      0.84      0.84       182\n","\n","   micro avg       0.92      0.90      0.91      2458\n","   macro avg       0.88      0.87      0.88      2458\n","weighted avg       0.92      0.90      0.91      2458\n","\n","Current leanring rate:  3.8011088011088013e-05\n","Current leanring rate:  3.8011088011088013e-05\n","Time:  126.66574668884277\n","======================================================\n","Training epoch: 6\n","Training loss epoch: 8.065608540519339 Training F1 epoch: 0.9489433904056763\n","Validation Loss: 9.109500739092384 Validation F1: 0.9202825428859738\n","New best f1 0.9202825428859738\n","              precision    recall  f1-score   support\n","\n","         DES       0.92      0.93      0.92      2276\n","         PRI       0.89      0.90      0.89       182\n","\n","   micro avg       0.91      0.93      0.92      2458\n","   macro avg       0.90      0.91      0.91      2458\n","weighted avg       0.91      0.93      0.92      2458\n","\n","Current leanring rate:  3.5474705474705475e-05\n","Current leanring rate:  3.5474705474705475e-05\n","Time:  126.859060049057\n","======================================================\n","Training epoch: 7\n","Training loss epoch: 5.613935293395663 Training F1 epoch: 0.9651480051480051\n","Validation Loss: 9.28876899760929 Validation F1: 0.9185905224787363\n","Current leanring rate:  3.293832293832294e-05\n","Current leanring rate:  3.293832293832294e-05\n","Time:  125.21355080604553\n","======================================================\n","Training epoch: 8\n","Training loss epoch: 4.337970170818392 Training F1 epoch: 0.9724212588277746\n","Validation Loss: 9.24555944223873 Validation F1: 0.9248090068355449\n","New best f1 0.9248090068355449\n","              precision    recall  f1-score   support\n","\n","         DES       0.92      0.94      0.93      2276\n","         PRI       0.89      0.91      0.90       182\n","\n","   micro avg       0.91      0.94      0.92      2458\n","   macro avg       0.90      0.92      0.91      2458\n","weighted avg       0.91      0.94      0.92      2458\n","\n","Current leanring rate:  3.0401940401940404e-05\n","Current leanring rate:  3.0401940401940404e-05\n","Time:  127.25442004203796\n","======================================================\n","Training epoch: 9\n","Training loss epoch: 3.409638618510929 Training F1 epoch: 0.9766867376872008\n","Validation Loss: 9.077119754311816 Validation F1: 0.9331713244228432\n","New best f1 0.9331713244228432\n","              precision    recall  f1-score   support\n","\n","         DES       0.93      0.94      0.94      2276\n","         PRI       0.90      0.92      0.91       182\n","\n","   micro avg       0.93      0.94      0.93      2458\n","   macro avg       0.92      0.93      0.92      2458\n","weighted avg       0.93      0.94      0.93      2458\n","\n","Current leanring rate:  2.7865557865557868e-05\n","Current leanring rate:  2.7865557865557868e-05\n","Time:  127.01784706115723\n","======================================================\n","Training epoch: 10\n","Training loss epoch: 2.7440098830259565 Training F1 epoch: 0.9804970925744867\n","Validation Loss: 9.6491615837389 Validation F1: 0.9232016210739615\n","Current leanring rate:  2.532917532917533e-05\n","Current leanring rate:  2.532917532917533e-05\n","Time:  125.52643084526062\n","======================================================\n","Training epoch: 11\n","Training loss epoch: 2.554711180306523 Training F1 epoch: 0.9812718666392262\n","Validation Loss: 10.998120917648565 Validation F1: 0.9195678271308523\n","Current leanring rate:  2.2792792792792794e-05\n","Current leanring rate:  2.2792792792792794e-05\n","Time:  125.90425443649292\n","======================================================\n","Training epoch: 12\n","Training loss epoch: 2.0095640088691087 Training F1 epoch: 0.9848290048855747\n","Validation Loss: 10.100573263533128 Validation F1: 0.9290765811275005\n","Current leanring rate:  2.025641025641026e-05\n","Current leanring rate:  2.025641025641026e-05\n","Time:  125.95587348937988\n","======================================================\n","Training epoch: 13\n","Training loss epoch: 1.7730634512145662 Training F1 epoch: 0.9877215515026971\n","Validation Loss: 10.56638623847336 Validation F1: 0.927793465106898\n","Current leanring rate:  1.772002772002772e-05\n","Current leanring rate:  1.772002772002772e-05\n","Time:  125.62022924423218\n","======================================================\n","Training epoch: 14\n","Training loss epoch: 1.4409990154328893 Training F1 epoch: 0.9901234567901235\n","Validation Loss: 10.828762367123463 Validation F1: 0.9364657814096016\n","New best f1 0.9364657814096016\n","              precision    recall  f1-score   support\n","\n","         DES       0.94      0.94      0.94      2276\n","         PRI       0.93      0.88      0.91       182\n","\n","   micro avg       0.94      0.93      0.94      2458\n","   macro avg       0.94      0.91      0.92      2458\n","weighted avg       0.94      0.93      0.94      2458\n","\n","Current leanring rate:  1.5183645183645184e-05\n","Current leanring rate:  1.5183645183645184e-05\n","Time:  127.13923287391663\n","======================================================\n","Training epoch: 15\n","Training loss epoch: 1.4121610714438184 Training F1 epoch: 0.9911021961631435\n","Validation Loss: 10.690644477885929 Validation F1: 0.9295431472081218\n","Current leanring rate:  1.2647262647262647e-05\n","Current leanring rate:  1.2647262647262647e-05\n","Time:  126.9798846244812\n","======================================================\n","Training epoch: 16\n","Training loss epoch: 1.065280434863815 Training F1 epoch: 0.9921842863019334\n","Validation Loss: 10.817267079170936 Validation F1: 0.9319562575941677\n","Current leanring rate:  1.0110880110880111e-05\n","Current leanring rate:  1.0110880110880111e-05\n","Time:  126.86056780815125\n","======================================================\n","Training epoch: 17\n","Training loss epoch: 0.941286014077442 Training F1 epoch: 0.9937320180846693\n","Validation Loss: 11.319300583802937 Validation F1: 0.9300813008130081\n","Current leanring rate:  7.574497574497574e-06\n","Current leanring rate:  7.574497574497574e-06\n","Time:  126.92934060096741\n","======================================================\n","Training epoch: 18\n","Training loss epoch: 0.8014964953146345 Training F1 epoch: 0.9955784061696658\n","Validation Loss: 11.580878586065573 Validation F1: 0.9353334684775998\n","Current leanring rate:  5.038115038115039e-06\n","Current leanring rate:  5.038115038115039e-06\n","Time:  127.09081244468689\n","======================================================\n","Training epoch: 19\n","Training loss epoch: 0.6377325005870048 Training F1 epoch: 0.9966589565664353\n","Validation Loss: 11.458980706220116 Validation F1: 0.9340080971659919\n","Current leanring rate:  2.5017325017325016e-06\n","Current leanring rate:  2.5017325017325016e-06\n","Time:  126.70985150337219\n","======================================================\n","Training epoch: 20\n","Training loss epoch: 0.5477976981407958 Training F1 epoch: 0.9969161184210525\n","Validation Loss: 11.43507627059853 Validation F1: 0.9349016426688298\n","Current leanring rate:  0.0\n","Current leanring rate:  0.0\n","Time:  126.89695262908936\n","======================================================\n"]}]},{"cell_type":"markdown","source":["# Temp\n"],"metadata":{"id":"7k1WqTO59A5Z"}},{"cell_type":"code","source":["from vncorenlp import VnCoreNLP\n","\n","# To perform word segmentation, POS tagging, NER and then dependency parsing\n","annotator = VnCoreNLP(\"/content/VnCoreNLP/VnCoreNLP-1.1.1.jar\", annotators=\"wseg,pos,ner,parse\", max_heap_size='-Xmx2g') \n"," \n","    \n","# Input \n","text = \"Ông Nguyễn Khắc Chúc  đang làm việc tại Đại học Quốc gia Hà Nội. Bà Lan, vợ ông Chúc, cũng làm việc tại đây.\"\n","\n","# To perform word segmentation, POS tagging, NER and then dependency parsing\n","annotated_text = annotator.annotate(text)\n","\n","# To perform word segmentation only\n","word_segmented_text = annotator.tokenize(text) \n"],"metadata":{"id":"mYzxKxlX9CYp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Input \n","text = \"thô lỗ\"\n","\n","# To perform word segmentation, POS tagging, NER and then dependency parsing\n","annotated_text = annotator.annotate(text)\n","\n","# To perform word segmentation only\n","word_segmented_text = annotator.tokenize(text) \n","word_segmented_text"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"32MdsTte-B-R","executionInfo":{"status":"ok","timestamp":1640146896575,"user_tz":-420,"elapsed":405,"user":{"displayName":"Quang Duy Tran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghu2xyMtK_2iyS9Voe4qtTbv8PTTDqItODbJlD0Uw=s64","userId":"16933642894382662697"}},"outputId":"56323918-7024-491d-b21d-a07ae9a78c5a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[['thô_lỗ']]"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["lines = ['mua được giá tốt lại được freeship mừng rơi nước_mắt đối_với tỉnh_lẻ thì tiền ship là 1 trở_ngại sản_phẩm quá ổn cảm_ơn shop cảm_ơn tiki this is english sentences cảm_ơn'] \n","tags = ['O,O,B-PRI,O,O,O,B-PRI,O,O,O,O,O,O,B-PRI,I-PRI,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O']\n","\n","ids, labels, masks = convert_lines(lines, tags, vocab, bpe, labels_to_ids)\n","for item in zip(ids[0], labels[0], masks[0]):\n","    print(f'{item[0]} \\t {item[1]} \\t {item[2]}')"],"metadata":{"id":"eSobWje-MLGt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"neLtVN_fXfeM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Data - legacy\n","\n"],"metadata":{"id":"CAnYaObi9HXf"}},{"cell_type":"code","source":["# data_path = './data/seq_tag/tokens_labeled_final.xlsx'\n","data_path = './data/seq_tag/tokens_labeled_no_whitelist.csv'\n","data = prepare_dataset(data_path)\n","data.head(10)"],"metadata":{"id":"Lx7keeHx_A0F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["path = data_path\n","if path.split('.')[-1]=='xlsx':\n","    with open(path, 'rb') as f:\n","        data = pd.read_excel(f)\n","else:\n","    data = pd.read_csv(path, encoding='utf-8')\n","data.drop(columns=['Unnamed: 0'], inplace=True)\n","\n","data.rename(columns={'sentence': 'Sentence #', 'tokens': 'Word', 'tag': 'Tag'}, inplace=True)\n","print(data.shape)\n","label = pd.read_csv('./data/seq_tag/tokens_labeled_sentiment.csv')\n","\n","print(label.shape)\n","# data['label'] =\n"],"metadata":{"id":"Sj2LlnvoQX_A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data['Sentence #'] = data['Sentence #'].apply(lambda x: f'Sentence: {int(x+1)}')\n","\n","print(\"Number of tags: {}\".format(len(data.Tag.unique())))\n","\n","frequencies = data.Tag.value_counts()\n","tags = {}\n","for tag, count in zip(frequencies.index, frequencies):\n","    if tag != \"O\":\n","        if tag[2:5] not in tags.keys():\n","            tags[tag[2:5]] = count\n","        else:\n","            tags[tag[2:5]] += count\n","    continue\n","\n","print(sorted(tags.items(), key=lambda x: x[1], reverse=True))\n","\n","labels_to_ids = {k: v for v, k in enumerate(data.Tag.unique())}\n","ids_to_labels = {v: k for v, k in enumerate(data.Tag.unique())}\n","print(labels_to_ids)\n","\n","data = data.fillna(method='ffill')\n","print(data)\n","if path.split('.')[-1]=='csv':\n","    data['sentence'] = data[['Sentence #','Word','Tag', 'label']].groupby(['Sentence #'])['Word'].transform(lambda x: ' '.join(x))\n","    data['word_labels'] = data[['Sentence #','Word','Tag', 'label']].groupby(['Sentence #'])['Tag'].transform(lambda x: ','.join(x))\n","if path.split('.')[-1]=='xlsx':\n","    data['sentence'] = data.groupby(['Sentence #'])['Word'].transform(lambda x: ' '.join(str(v) for v in x))\n","    data['word_labels'] = data.groupby(['Sentence #'])['Tag'].transform(lambda x: ','.join(str(v) for v in x))\n","    # data['label'] = data.groupby(['Sentence #'])['label'].mean()\n","data = data.drop_duplicates(subset='sentence').reset_index(drop=True)\n"],"metadata":{"id":"Jl6IRWjWZxDI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["label = []\n","for sent in data['Sentence #']:\n","    sent_id = int(sent.split(' ')[-1])\n","    label.append(df.label.iloc[sent_id-1])"],"metadata":{"id":"DfwcqFZBddmY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = pd.read_excel('./data/clean/final6.xlsx')\n","df.drop(columns='Unnamed: 0', inplace=True)\n","df"],"metadata":{"id":"gMgiFxq-dUT4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data['label'] = label"],"metadata":{"id":"5SXWwbpieH2e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# data.drop(columns=['Sentence #','Word','Tag'], inplace=True)\n","data.drop_duplicates(inplace=True)\n","data"],"metadata":{"id":"A0whzbX0eLJO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data.to_csv('./data/joint/data_joint.csv')"],"metadata":{"id":"r4o7Ymn2enJ_"},"execution_count":null,"outputs":[]}]}