{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"seq_tag_w2v_crf.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1hYz1MDCavoMFrK5wO1hkRnkMJQT9epk1","authorship_tag":"ABX9TyNYn7hrcQozHLWM8hpgTry1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ib7SWUIP8cOg","executionInfo":{"status":"ok","timestamp":1639972988065,"user_tz":-420,"elapsed":5925,"user":{"displayName":"Quang Duy Trần","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvMaEX5IKcYvanQuv2HTQEdjP5mTCjGM4CkVJX=s64","userId":"16019943656023573816"}},"outputId":"eda5b736-ff5b-42fa-aaac-499f92227812"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7fefb921dd30>"]},"metadata":{},"execution_count":1}],"source":["import torch\n","import torch.autograd as autograd\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","torch.manual_seed(1)"]},{"cell_type":"markdown","source":["### Bi-LSTM CRF"],"metadata":{"id":"o_-ZYu4WHUNG"}},{"cell_type":"code","source":["def argmax(vec):\n","    # return the argmax as a python int\n","    _, idx = torch.max(vec, 1)\n","    return idx.item()\n","\n","\n","def prepare_sequence(seq, to_ix):\n","    idxs = [to_ix[w] for w in seq]\n","    return torch.tensor(idxs, dtype=torch.long)\n","\n","\n","# Compute log sum exp in a numerically stable way for the forward algorithm\n","def log_sum_exp(vec):\n","    max_score = vec[0, argmax(vec)]\n","    max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n","    return max_score + \\\n","        torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))"],"metadata":{"id":"JVsOC8QBAYgH","executionInfo":{"status":"ok","timestamp":1639972988066,"user_tz":-420,"elapsed":4,"user":{"displayName":"Quang Duy Trần","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvMaEX5IKcYvanQuv2HTQEdjP5mTCjGM4CkVJX=s64","userId":"16019943656023573816"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["class BiLSTM_CRF(nn.Module):\n","\n","    def __init__(self, vocab_size, tag_to_ix, embedding_dim, hidden_dim):\n","        super(BiLSTM_CRF, self).__init__()\n","        self.embedding_dim = embedding_dim\n","        self.hidden_dim = hidden_dim\n","        self.vocab_size = vocab_size\n","        self.tag_to_ix = tag_to_ix\n","        self.tagset_size = len(tag_to_ix)\n","\n","        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n","        self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2,\n","                            num_layers=1, bidirectional=True)\n","\n","        # Maps the output of the LSTM into tag space.\n","        self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size)\n","\n","        # Matrix of transition parameters.  Entry i,j is the score of\n","        # transitioning *to* i *from* j.\n","        self.transitions = nn.Parameter(\n","            torch.randn(self.tagset_size, self.tagset_size))\n","\n","        # These two statements enforce the constraint that we never transfer\n","        # to the start tag and we never transfer from the stop tag\n","        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n","        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n","\n","        self.hidden = self.init_hidden()\n","\n","    def init_hidden(self):\n","        return (torch.randn(2, 1, self.hidden_dim // 2),\n","                torch.randn(2, 1, self.hidden_dim // 2))\n","\n","    def _forward_alg(self, feats):\n","        # Do the forward algorithm to compute the partition function\n","        init_alphas = torch.full((1, self.tagset_size), -10000.)\n","        # START_TAG has all of the score.\n","        init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n","\n","        # Wrap in a variable so that we will get automatic backprop\n","        forward_var = init_alphas\n","\n","        # Iterate through the sentence\n","        for feat in feats:\n","            alphas_t = []  # The forward tensors at this timestep\n","            for next_tag in range(self.tagset_size):\n","                # broadcast the emission score: it is the same regardless of\n","                # the previous tag\n","                emit_score = feat[next_tag].view(\n","                    1, -1).expand(1, self.tagset_size)\n","                # the ith entry of trans_score is the score of transitioning to\n","                # next_tag from i\n","                trans_score = self.transitions[next_tag].view(1, -1)\n","                # The ith entry of next_tag_var is the value for the\n","                # edge (i -> next_tag) before we do log-sum-exp\n","                next_tag_var = forward_var + trans_score + emit_score\n","                # The forward variable for this tag is log-sum-exp of all the\n","                # scores.\n","                alphas_t.append(log_sum_exp(next_tag_var).view(1))\n","            forward_var = torch.cat(alphas_t).view(1, -1)\n","        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n","        alpha = log_sum_exp(terminal_var)\n","        return alpha\n","\n","    def _get_lstm_features(self, sentence):\n","        self.hidden = self.init_hidden()\n","        embeds = self.word_embeds(sentence).view(len(sentence), 1, -1)\n","        lstm_out, self.hidden = self.lstm(embeds, self.hidden)\n","        lstm_out = lstm_out.view(len(sentence), self.hidden_dim)\n","        lstm_feats = self.hidden2tag(lstm_out)\n","        return lstm_feats\n","\n","    def _score_sentence(self, feats, tags):\n","        # Gives the score of a provided tag sequence\n","        score = torch.zeros(1)\n","        tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long), tags])\n","        for i, feat in enumerate(feats):\n","            score = score + \\\n","                self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n","        score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n","        return score\n","\n","    def _viterbi_decode(self, feats):\n","        backpointers = []\n","\n","        # Initialize the viterbi variables in log space\n","        init_vvars = torch.full((1, self.tagset_size), -10000.)\n","        init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n","\n","        # forward_var at step i holds the viterbi variables for step i-1\n","        forward_var = init_vvars\n","        for feat in feats:\n","            bptrs_t = []  # holds the backpointers for this step\n","            viterbivars_t = []  # holds the viterbi variables for this step\n","\n","            for next_tag in range(self.tagset_size):\n","                # next_tag_var[i] holds the viterbi variable for tag i at the\n","                # previous step, plus the score of transitioning\n","                # from tag i to next_tag.\n","                # We don't include the emission scores here because the max\n","                # does not depend on them (we add them in below)\n","                next_tag_var = forward_var + self.transitions[next_tag]\n","                best_tag_id = argmax(next_tag_var)\n","                bptrs_t.append(best_tag_id)\n","                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n","            # Now add in the emission scores, and assign forward_var to the set\n","            # of viterbi variables we just computed\n","            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n","            backpointers.append(bptrs_t)\n","\n","        # Transition to STOP_TAG\n","        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n","        best_tag_id = argmax(terminal_var)\n","        path_score = terminal_var[0][best_tag_id]\n","\n","        # Follow the back pointers to decode the best path.\n","        best_path = [best_tag_id]\n","        for bptrs_t in reversed(backpointers):\n","            best_tag_id = bptrs_t[best_tag_id]\n","            best_path.append(best_tag_id)\n","        # Pop off the start tag (we dont want to return that to the caller)\n","        start = best_path.pop()\n","        assert start == self.tag_to_ix[START_TAG]  # Sanity check\n","        best_path.reverse()\n","        return path_score, best_path\n","\n","    def neg_log_likelihood(self, sentence, tags):\n","        feats = self._get_lstm_features(sentence)\n","        forward_score = self._forward_alg(feats)\n","        gold_score = self._score_sentence(feats, tags)\n","        return forward_score - gold_score\n","\n","    def forward(self, sentence):  # dont confuse this with _forward_alg above.\n","        # Get the emission scores from the BiLSTM\n","        # print(sentence)\n","        lstm_feats = self._get_lstm_features(sentence)\n","\n","        # Find the best path, given the features.\n","        score, tag_seq = self._viterbi_decode(lstm_feats)\n","        return score, tag_seq"],"metadata":{"id":"cmfFpLX_AZXL","executionInfo":{"status":"ok","timestamp":1639973078673,"user_tz":-420,"elapsed":3,"user":{"displayName":"Quang Duy Trần","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvMaEX5IKcYvanQuv2HTQEdjP5mTCjGM4CkVJX=s64","userId":"16019943656023573816"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["START_TAG = \"<START>\"\n","STOP_TAG = \"<STOP>\"\n","EMBEDDING_DIM = 5\n","HIDDEN_DIM = 4\n","\n","# Make up some training data\n","training_data = [(\n","    \"the wall street journal reported today that apple corporation made money\".split(),\n","    \"B I I I O O O B I O O\".split()\n","), (\n","    \"georgia tech is a university in georgia\".split(),\n","    \"B I O O O O B\".split()\n",")]\n","\n","word_to_ix = {}\n","for sentence, tags in training_data:\n","    for word in sentence:\n","        if word not in word_to_ix:\n","            word_to_ix[word] = len(word_to_ix)\n","\n","tag_to_ix = {\"B\": 0, \"I\": 1, \"O\": 2, START_TAG: 3, STOP_TAG: 4}\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m4YdW_2pAawr","executionInfo":{"status":"ok","timestamp":1639972996143,"user_tz":-420,"elapsed":7657,"user":{"displayName":"Quang Duy Trần","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvMaEX5IKcYvanQuv2HTQEdjP5mTCjGM4CkVJX=s64","userId":"16019943656023573816"}},"outputId":"ada48be0-0a45-489e-fd9b-23e80a7865d2"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["(tensor(2.6907), [1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1])\n","(tensor(20.4906), [0, 1, 1, 1, 2, 2, 2, 0, 1, 2, 2])\n"]}]},{"cell_type":"code","source":["tag_to_ix"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U9B8_R2KBtDJ","executionInfo":{"status":"ok","timestamp":1639973312625,"user_tz":-420,"elapsed":302,"user":{"displayName":"Quang Duy Trần","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvMaEX5IKcYvanQuv2HTQEdjP5mTCjGM4CkVJX=s64","userId":"16019943656023573816"}},"outputId":"a2d7f915-9c39-42f1-e993-a856f724cf21"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'<START>': 3, '<STOP>': 4, 'B': 0, 'I': 1, 'O': 2}"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM)\n","optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)\n","\n","# Check predictions before training\n","with torch.no_grad():\n","    precheck_sent = prepare_sequence(training_data[0][0], word_to_ix)\n","    precheck_tags = torch.tensor([tag_to_ix[t] for t in training_data[0][1]], dtype=torch.long)\n","    model(precheck_sent)\n","    # print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xx-oUrkxAhq7","executionInfo":{"status":"ok","timestamp":1639973104536,"user_tz":-420,"elapsed":2,"user":{"displayName":"Quang Duy Trần","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvMaEX5IKcYvanQuv2HTQEdjP5mTCjGM4CkVJX=s64","userId":"16019943656023573816"}},"outputId":"15de38a6-3795-4c6e-f4a2-62589b02e022"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10])\n"]}]},{"cell_type":"code","source":["# Make sure prepare_sequence from earlier in the LSTM section is loaded\n","for epoch in range(\n","        300):  # again, normally you would NOT do 300 epochs, it is toy data\n","    for sentence, tags in training_data:\n","        # Step 1. Remember that Pytorch accumulates gradients.\n","        # We need to clear them out before each instance\n","        optimizer.zero_grad()\n","\n","        # Step 2. Get our inputs ready for the network, that is,\n","        # turn them into Tensors of word indices.\n","        sentence_in = prepare_sequence(sentence, word_to_ix)\n","        targets = torch.tensor([tag_to_ix[t] for t in tags], dtype=torch.long)\n","\n","        # Step 3. Run our forward pass.\n","        loss = model.neg_log_likelihood(sentence_in, targets)\n","\n","        # Step 4. Compute the loss, gradients, and update the parameters by\n","        # calling optimizer.step()\n","        loss.backward()\n","        optimizer.step()\n","\n","# Check predictions after training\n","with torch.no_grad():\n","    precheck_sent = prepare_sequence(training_data[0][0], word_to_ix)\n","    print(model(precheck_sent))\n","# We got it!"],"metadata":{"id":"wVCTVcuyAc4O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["training_data[0][0], word_to_ix"],"metadata":{"id":"kZlH0_pUApIE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["precheck_sent"],"metadata":{"id":"6VDz-sarAlxj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"HKxz8zBYGoEQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Word2Vec"],"metadata":{"id":"GBJXgHfXHX2f"}},{"cell_type":"code","source":["!pip install vncorenlp\n","!mkdir -p vncorenlp/models/wordsegmenter\n","!wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/VnCoreNLP-1.1.1.jar\n","!wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/vi-vocab\n","!wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/wordsegmenter.rdr\n","!mv VnCoreNLP-1.1.1.jar vncorenlp/ \n","!mv vi-vocab vncorenlp/models/wordsegmenter/\n","!mv wordsegmenter.rdr vncorenlp/models/wordsegmenter/"],"metadata":{"id":"dGtAGpLgIlOd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install nltk -q\n","!pip install gensim -q"],"metadata":{"id":"fF1RYSQYHZNZ","executionInfo":{"status":"ok","timestamp":1639975248371,"user_tz":-420,"elapsed":7063,"user":{"displayName":"Quang Duy Trần","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvMaEX5IKcYvanQuv2HTQEdjP5mTCjGM4CkVJX=s64","userId":"16019943656023573816"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["!git clone https://github.com/facebookresearch/fastText.git"],"metadata":{"id":"6qxtYsvmI9NS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd fastText\n","!python setup.py install"],"metadata":{"id":"c5wFpcnUJM72"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import fasttext.util\n","fasttext.util.download_model('vi', if_exists='ignore')  # English\n","ft = fasttext.load_model('cc.vi.300.bin')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jgnLe5UsJVv7","executionInfo":{"status":"ok","timestamp":1639977172962,"user_tz":-420,"elapsed":1807295,"user":{"displayName":"Quang Duy Trần","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvMaEX5IKcYvanQuv2HTQEdjP5mTCjGM4CkVJX=s64","userId":"16019943656023573816"}},"outputId":"2b0e74f2-7a5d-4636-ced6-3202ad5b7a08"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.vi.300.bin.gz\n","\n"]}]},{"cell_type":"code","source":["ft = fasttext.load_model('cc.vi.300.vec')"],"metadata":{"id":"rsrtNxX6J4KT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import sys\n","import time\n","import datetime\n","import math\n","\n","import numpy as np\n","import pandas as pd\n","from tqdm.notebook import tqdm\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import f1_score\n","import tensorflow as tf\n","# import tensorflow_addons as tfa\n","import keras.backend as K\n","\n","import warnings\n","from gensim.models import FastText\n","warnings.filterwarnings(\"ignore\")\n"],"metadata":{"id":"ejx3-gPcHmOn","executionInfo":{"status":"ok","timestamp":1639979841692,"user_tz":-420,"elapsed":15068,"user":{"displayName":"Quang Duy Trần","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvMaEX5IKcYvanQuv2HTQEdjP5mTCjGM4CkVJX=s64","userId":"16019943656023573816"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["len(ft.words)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lj8QtnBGakJm","executionInfo":{"status":"ok","timestamp":1639979856434,"user_tz":-420,"elapsed":3,"user":{"displayName":"Quang Duy Trần","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvMaEX5IKcYvanQuv2HTQEdjP5mTCjGM4CkVJX=s64","userId":"16019943656023573816"}},"outputId":"d1e6a33f-2d8f-44a0-c48e-5294df6c508f"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2000000"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["ft.get_nearest_neighbors(\"free\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rxOwZk-RatkG","executionInfo":{"status":"ok","timestamp":1639984201315,"user_tz":-420,"elapsed":484,"user":{"displayName":"Quang Duy Trần","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvMaEX5IKcYvanQuv2HTQEdjP5mTCjGM4CkVJX=s64","userId":"16019943656023573816"}},"outputId":"71a7ad3d-617c-4b35-ac98-2574ff3d55ec"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(0.6372799277305603, 'free_free'),\n"," (0.5946022272109985, 'freee'),\n"," (0.5665760040283203, 'it_free'),\n"," (0.5653821229934692, 'hit_counters'),\n"," (0.5630102753639221, 'free1'),\n"," (0.5554265975952148, 'to_play'),\n"," (0.5541876554489136, 'free_ship'),\n"," (0.5538107752799988, 'freewebs'),\n"," (0.5356706976890564, 'mufree'),\n"," (0.5343804359436035, 'free_software')]"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["pd.options.display.max_colwidth=1000\n","train_df = pd.read_csv(\"../input/vietai-dataset/assignment4-data/Assignment4/train.csv\")\n","train_df.head()"],"metadata":{"id":"UreiJ4xEIt7X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["words_list = np.load('../input/vietai-dataset/assignment4-data/Assignment4/words_list.npy')\n","print('Prunned vocabulary loaded!')\n","words_list = words_list.tolist()\n","word_vectors = np.load('../input/vietai-dataset/assignment4-data/Assignment4/word_vectors.npy')\n","word_vectors = np.float32(word_vectors)\n","print ('Word embedding matrix loaded!')\n","print('Size of the vocabulary: ', len(words_list))\n","print('Size of the word embedding matrix: ', word_vectors.shape)"],"metadata":{"id":"15pH0hXLIzxv"},"execution_count":null,"outputs":[]}]}