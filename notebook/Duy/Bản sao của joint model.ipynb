{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Bản sao của joint model.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"8525dc9e42714e7b956566591b333a68":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_3b26069809f744d4bff3fb0e3855bf1b","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9fe2daed5713473aad60f170629a6daf","IPY_MODEL_eee2a10dc173472491d74e28d87d626e","IPY_MODEL_515b2e6b53484a849a4420bcef578179"]}},"3b26069809f744d4bff3fb0e3855bf1b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9fe2daed5713473aad60f170629a6daf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6cf55af8597641eaba39d7e8c57478e4","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4439960faa744b308e39df2648fed8a0"}},"eee2a10dc173472491d74e28d87d626e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b1f6395b70da45119ee565e914a27b40","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":542923308,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":542923308,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_34435adef75746248d08bddb901ad973"}},"515b2e6b53484a849a4420bcef578179":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_839ff49e51214c8cabd0152221aed72e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 518M/518M [00:15&lt;00:00, 27.3MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6d005a69a52a47c0b6bc5ee7f86b044c"}},"6cf55af8597641eaba39d7e8c57478e4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4439960faa744b308e39df2648fed8a0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b1f6395b70da45119ee565e914a27b40":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"34435adef75746248d08bddb901ad973":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"839ff49e51214c8cabd0152221aed72e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"6d005a69a52a47c0b6bc5ee7f86b044c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"EluFoXpstkQw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1640282612145,"user_tz":-420,"elapsed":20702,"user":{"displayName":"Trinh Truong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GibwjDAT5JHasAFlEGN-kjgr2JnHi7XIqtdSxt4=s64","userId":"05537025703764185240"}},"outputId":"9906a3b2-a78f-40e8-e19a-7a98c4a6f71c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive._mount('/content/drive')"]},{"cell_type":"code","source":["!pip install transformers seqeval[gpu] -q\n","!pip install fairseq -q\n","!pip install fastBPE -q\n","!pip install pytorch-crf -q"],"metadata":{"id":"L9wP2b1St23U","executionInfo":{"status":"ok","timestamp":1640282651045,"user_tz":-420,"elapsed":38905,"user":{"displayName":"Trinh Truong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GibwjDAT5JHasAFlEGN-kjgr2JnHi7XIqtdSxt4=s64","userId":"05537025703764185240"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"159248c7-4e8f-430e-ae64-7b718da446a0"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 3.4 MB 12.1 MB/s \n","\u001b[K     |████████████████████████████████| 43 kB 2.0 MB/s \n","\u001b[K     |████████████████████████████████| 596 kB 39.3 MB/s \n","\u001b[K     |████████████████████████████████| 895 kB 46.8 MB/s \n","\u001b[K     |████████████████████████████████| 3.3 MB 45.0 MB/s \n","\u001b[K     |████████████████████████████████| 61 kB 462 kB/s \n","\u001b[?25h  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[K     |████████████████████████████████| 1.7 MB 12.3 MB/s \n","\u001b[K     |████████████████████████████████| 145 kB 52.3 MB/s \n","\u001b[K     |████████████████████████████████| 90 kB 9.6 MB/s \n","\u001b[K     |████████████████████████████████| 74 kB 3.2 MB/s \n","\u001b[K     |████████████████████████████████| 112 kB 35.1 MB/s \n","\u001b[?25h  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for fastBPE (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/NLP/project_nlp"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gxBrCjTUt3-A","executionInfo":{"status":"ok","timestamp":1640282651046,"user_tz":-420,"elapsed":26,"user":{"displayName":"Trinh Truong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GibwjDAT5JHasAFlEGN-kjgr2JnHi7XIqtdSxt4=s64","userId":"05537025703764185240"}},"outputId":"2685e2f0-c395-43a5-c42d-7316b347e2f0"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/NLP/project_nlp\n"]}]},{"cell_type":"markdown","source":["### Import"],"metadata":{"id":"La9hXz5guXCE"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader, TensorDataset\n","import torch.nn.functional as F\n","from torchcrf import CRF\n","\n","from transformers import RobertaConfig, RobertaPreTrainedModel, RobertaModel, RobertaForTokenClassification\n","from transformers import AdamW, get_linear_schedule_with_warmup, get_constant_schedule\n","from transformers.modeling_outputs import TokenClassifierOutput\n","\n","import seqeval\n","from seqeval.metrics import classification_report, f1_score\n","\n","import pandas as pd\n","import numpy as np\n","import argparse\n","import time\n","import tqdm\n","from sklearn import metrics\n","\n","from fairseq.data.encoders.fastbpe import fastBPE\n","from fairseq.data import Dictionary\n","\n","from sklearn.utils.class_weight import compute_class_weight\n","\n","from src.dataset import *"],"metadata":{"id":"SwLPFLwbuDGc","executionInfo":{"status":"ok","timestamp":1640282662485,"user_tz":-420,"elapsed":11459,"user":{"displayName":"Trinh Truong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GibwjDAT5JHasAFlEGN-kjgr2JnHi7XIqtdSxt4=s64","userId":"05537025703764185240"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'"],"metadata":{"id":"zxVOlPeJuEwk","executionInfo":{"status":"ok","timestamp":1640282662486,"user_tz":-420,"elapsed":11,"user":{"displayName":"Trinh Truong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GibwjDAT5JHasAFlEGN-kjgr2JnHi7XIqtdSxt4=s64","userId":"05537025703764185240"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["### Parameters\n"],"metadata":{"id":"mTckvMKzuS9F"}},{"cell_type":"code","source":["BATCHSIZE_TRAIN = 8\n","BATCHSIZE_VAL = 4\n","LEARNING_RATE = 1e-5\n","MAX_LEN = 128\n","NUM_EPOCH = 20\n","SEED = 42\n","NUM_CLASS = 5\n","MAX_GRAD_NORM = 1"],"metadata":{"id":"nfX8HcPSuGP0","executionInfo":{"status":"ok","timestamp":1640282709673,"user_tz":-420,"elapsed":375,"user":{"displayName":"Trinh Truong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GibwjDAT5JHasAFlEGN-kjgr2JnHi7XIqtdSxt4=s64","userId":"05537025703764185240"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["### Data"],"metadata":{"id":"grNHZvOsuRQm"}},{"cell_type":"code","source":["data = pd.read_csv('./data/joint/data_joint.csv')\n","print(data)\n","\n","parser = argparse.ArgumentParser()\n","parser.add_argument('--bpe-codes', \n","    default=\"./PhoBERT_base_transformers/bpe.codes\",\n","    required=False,\n","    type=str,\n","    help='path to fastBPE BPE'\n",")\n","args, unknown = parser.parse_known_args()\n","bpe = fastBPE(args)\n","\n","# Load the dictionary\n","vocab = Dictionary()\n","vocab.add_from_file(\"./PhoBERT_base_transformers/dict.txt\")\n","\n","labels_to_ids = {'B-DES': 1, 'B-PRI': 3, 'I-DES': 2, 'I-PRI': 4, 'O': 0, 'X': -100}\n","ids_to_labels = {0: 'O', 1: 'B-DES', 2: 'I-DES', 3:'B-PRI', 4:'I-PRI'}\n","\n","X, Y_label, Y_mask = convert_lines(\n","    data.sentence.values, \n","    data.word_labels.values, \n","    vocab, \n","    bpe, \n","    labels_to_ids, \n","    max_sequence_length=MAX_LEN)\n","\n","convert_type = {-1: 0,\n","                0:1,\n","                1:2}\n","Y_sent = data['label'].map(convert_type).astype(int).values\n","\n","\n","print('X shape: ', X.shape)\n","print('Y label shape', Y_label.shape)\n","print('Y mask shape', Y_mask.shape)\n","print('Y sent shape', Y_sent.shape)\n","\n","train_size = 0.8\n","def train_test_split(data, train_size):\n","    data_df = pd.DataFrame(data)\n","    data_train = data_df.sample(frac = train_size, random_state=SEED)\n","    data_test = data_df.drop(data_train.index).reset_index(drop=True)\n","    data_train = data_train.reset_index(drop=True)\n","    return data_train.values, data_test.values\n","\n","X_train, X_test = train_test_split(X, train_size)\n","Y_label_train, Y_label_test = train_test_split(Y_label, train_size)\n","Y_mask_train, Y_mask_test = train_test_split(Y_mask, train_size)\n","Y_sent_train, Y_sent_test = train_test_split(Y_sent, train_size)\n","\n","class_weight = compute_class_weight(\n","    class_weight='balanced', \n","    classes = np.array([0,1,2,3,4]), \n","    y=Y_label_train.flatten()[Y_label_train.flatten()>=0])\n","\n","print('class_weight for sequence labeling using CrossEntropyLoss', class_weight)\n","\n","\n","train_dataset = TensorDataset(\n","    torch.tensor(X_train,dtype=torch.long), \n","    torch.tensor(Y_label_train,dtype=torch.long),\n","    torch.tensor(Y_sent_train,dtype=torch.long)\n","    )\n","valid_dataset = TensorDataset(\n","    torch.tensor(X_test,dtype=torch.long), \n","    torch.tensor(Y_label_test,dtype=torch.long),\n","    torch.tensor(Y_sent_test,dtype=torch.long)\n","    )\n","\n","train_loader = torch.utils.data.DataLoader(\n","    train_dataset, \n","    batch_size=BATCHSIZE_TRAIN, \n","    shuffle=True,\n","    drop_last=True\n","    )\n","valid_loader = torch.utils.data.DataLoader(\n","    valid_dataset, \n","    batch_size=BATCHSIZE_VAL, \n","    shuffle=False,\n","    drop_last=True\n","    )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W9_8m6TSuIcD","executionInfo":{"status":"ok","timestamp":1640282666152,"user_tz":-420,"elapsed":3670,"user":{"displayName":"Trinh Truong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GibwjDAT5JHasAFlEGN-kjgr2JnHi7XIqtdSxt4=s64","userId":"05537025703764185240"}},"outputId":"a248ca23-1117-4c55-9423-2e111883f3f8"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["      Unnamed: 0  ... label\n","0              0  ...    -1\n","1              1  ...    -1\n","2              2  ...    -1\n","3              3  ...    -1\n","4              4  ...    -1\n","...          ...  ...   ...\n","3652        3652  ...     1\n","3653        3653  ...     1\n","3654        3654  ...     1\n","3655        3655  ...     1\n","3656        3656  ...     1\n","\n","[3657 rows x 4 columns]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 3657/3657 [00:01<00:00, 2573.16it/s]"]},{"output_type":"stream","name":"stdout","text":["X shape:  (3657, 128)\n","Y label shape (3657, 128)\n","Y mask shape (3657, 128)\n","Y sent shape (3657,)\n","class_weight for sequence labeling using CrossEntropyLoss [ 0.24363978  1.55168755  6.34937644 16.17223529 31.45629291]\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"markdown","source":["### Config"],"metadata":{"id":"XbMowOE7uazr"}},{"cell_type":"code","source":["class argu():\n","    def __init__(self):\n","        self.dict_path = \"./PhoBERT_base_transformers/dict.txt\"\n","        self.config_path = \"./PhoBERT_base_transformers/config.json\"\n","        self.max_sequence_length = MAX_LEN\n","        self.accumulation_steps = 1\n","        self.epochs = NUM_EPOCH\n","        self.seed = SEED\n","        self.bpe_codes = \"./PhoBERT_base_transformers/bpe.codes\"\n","args = argu()\n","\n","config = RobertaConfig.from_pretrained(\n","    args.config_path,\n","    output_hidden_states=True,\n","    return_dict=True,\n","    num_labels=NUM_CLASS,\n","    pad_token_id = 1,\n","    bos_token_id = 0,\n","    eos_token_id = 2,\n","    attention_probs_dropout_prob = 0.1,\n","    classifier_dropout=0.5,\n","    gradient_checkpointing=False,\n","    hidden_act=\"gelu\",\n","    hidden_dropout_prob=0.1,\n","    hidden_size=768,\n","    initializer_range=0.02,\n","    intermediate_size=3072,\n","    layer_norm_eps=1e-05,\n","    max_position_embeddings=258,\n","    model_type=\"roberta\",\n","    num_attention_heads=12,\n","    num_hidden_layers=12,\n","    position_embedding_type=\"absolute\",\n","    tokenizer_class=\"PhobertTokenizer\",\n","    transformers_version=\"4.15.0\",\n","    type_vocab_size=1,\n","    use_cache=True,\n","    vocab_size=64001\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jdBU8-Dfub5_","executionInfo":{"status":"ok","timestamp":1640282713803,"user_tz":-420,"elapsed":3,"user":{"displayName":"Trinh Truong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GibwjDAT5JHasAFlEGN-kjgr2JnHi7XIqtdSxt4=s64","userId":"05537025703764185240"}},"outputId":"1581e812-0ac3-4317-8990-1bed03152248"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["You are using a model of type bert to instantiate a model of type roberta. This is not supported for all configurations of models and can yield errors.\n"]}]},{"cell_type":"markdown","source":["### Train test function"],"metadata":{"id":"vncJ_xAUugVZ"}},{"cell_type":"code","source":["def softmax(x):\n","    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n","    return np.exp(x) / np.sum(np.exp(x), axis=0)"],"metadata":{"id":"4R3oLXdMyFqf","executionInfo":{"status":"ok","timestamp":1640282715499,"user_tz":-420,"elapsed":4,"user":{"displayName":"Trinh Truong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GibwjDAT5JHasAFlEGN-kjgr2JnHi7XIqtdSxt4=s64","userId":"05537025703764185240"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["def train_crf(epoch, verbose = False):\n","    tr_loss, tr_accuracy = 0, 0\n","    nb_tr_examples, nb_tr_steps = 0, 0\n","    tr_preds, tr_labels = [], []\n","    labels_sent_ar = []\n","    y_preds = None\n","    model.train()\n","    \n","    for idx, batch in enumerate(train_loader):\n","        ids, labels, labels_sent = batch\n","        ids = ids.to(device)\n","        labels = labels.to(device)\n","        labels_sent = labels_sent.to(device)\n","        mask = ids!=1\n","        \n","        outputs = model(input_ids=ids, \n","                        attention_mask=mask, \n","                        labels=labels, \n","                        labels_sent=labels_sent)\n","        \n","        loss = outputs[0]\n","        y_pred = outputs[2].squeeze().detach().cpu().numpy()\n","        y_preds = np.atleast_1d(y_pred) if y_preds is None else np.concatenate([y_preds, np.atleast_1d(y_pred)])\n","                \n","        tr_loss += loss.item()\n","\n","        nb_tr_steps += 1\n","        nb_tr_examples += labels.size(0)\n","        \n","        if idx % 100==0 and verbose:\n","            loss_step = tr_loss/nb_tr_steps\n","            print(f\"Training loss per 100 training steps: {loss_step}\")\n","           \n","        flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n","        flattened_predictions = outputs[1].view(-1)\n","        \n","        # only compute accuracy at active labels\n","        active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n","        active_labels = torch.where(active_accuracy, labels.view(-1), torch.tensor(-100).type_as(labels))\n","        \n","        labels = torch.masked_select(flattened_targets, active_accuracy)\n","        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n","        \n","        tr_labels.extend(labels)\n","        tr_preds.extend(predictions)\n","        labels_sent_ar.extend(labels_sent.cpu().detach().numpy())\n","    \n","        # gradient clipping\n","        torch.nn.utils.clip_grad_norm_(\n","            parameters=model.parameters(), max_norm=MAX_GRAD_NORM\n","        )\n","        \n","        # backward pass\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        try: \n","            scheduler0.step()\n","        except:\n","            scheduler.step()\n","            \n","    epoch_loss = tr_loss / nb_tr_steps\n","    tr_accuracy = tr_accuracy / nb_tr_steps\n","\n","    labels = [ids_to_labels[id.item()] for id in tr_labels]\n","    predictions = [ids_to_labels[id.item()] for id in tr_preds]\n","\n","    f1_token = seqeval.metrics.f1_score([labels], [predictions])\n","    val_preds = np.argmax(softmax(y_preds), axis=1)\n","    # print(val_preds)\n","    # print(np.concatenate(labels_sent_ar))\n","    f1_sent = metrics.f1_score(labels_sent_ar, val_preds, average='micro')\n","\n","    print(f\"Train loss: {epoch_loss}\", \n","          f\"F1 tagging: {f1_token}\", \n","          f\"F1 classification: {f1_sent}\")\n","\n","\n","def valid_crf(model, test_loader, verbose=False):\n","    # put model in evaluation mode\n","    model.eval()\n","    \n","    eval_loss, eval_accuracy = 0, 0\n","    nb_eval_examples, nb_eval_steps = 0, 0\n","    eval_preds, eval_labels = [], []\n","    labels_sent_ar = []\n","    val_preds = None\n","    \n","    with torch.no_grad():\n","        for idx, batch in enumerate(test_loader):\n","            \n","            ids, labels, labels_sent = batch\n","            ids = ids.to(device)\n","            labels = labels.to(device)\n","            labels_sent = labels_sent.to(device)\n","            mask = ids!=1 \n","\n","            outputs = model(input_ids=ids, \n","                            attention_mask=mask, \n","                            labels=labels, \n","                            labels_sent=labels_sent)\n","            loss = outputs[0]\n","            eval_loss += loss.item()\n","\n","            y_pred = outputs[2].squeeze().detach().cpu().numpy()\n","            val_preds = np.atleast_1d(y_pred) if val_preds is None else np.concatenate([val_preds, np.atleast_1d(y_pred)])\n","\n","            nb_eval_steps += 1\n","            nb_eval_examples += labels.size(0)\n","        \n","            if idx % 100==0 and verbose:\n","                loss_step = eval_loss/nb_eval_steps\n","                print(f\"Validation loss per 100 evaluation steps: {loss_step}\")\n","              \n","            # compute evaluation accuracy\n","            flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n","            flattened_predictions = outputs[1].view(-1)\n","            \n","            # only compute accuracy at active labels\n","            active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n","            active_labels = torch.where(active_accuracy, labels.view(-1), torch.tensor(-100).type_as(labels))\n","\n","            labels = torch.masked_select(flattened_targets, active_accuracy)\n","            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n","            \n","            eval_labels.extend(labels)\n","            eval_preds.extend(predictions)\n","            labels_sent_ar.extend(labels_sent.cpu().detach().numpy())\n","            \n","\n","    labels = [ids_to_labels[id.item()] for id in eval_labels]\n","    predictions = [ids_to_labels[id.item()] for id in eval_preds]\n","    \n","    eval_loss = eval_loss / nb_eval_steps\n","    f1_token = seqeval.metrics.f1_score([labels], [predictions])\n","    sent_preds = np.argmax(softmax(val_preds), axis=1)\n","    f1_sent = metrics.f1_score(labels_sent_ar, sent_preds, average='micro')\n","\n","    print(f\"Train loss: {eval_loss}\", \n","          f\"F1 tagging: {f1_token}\", \n","          f\"F1 classification: {f1_sent}\")\n","\n","    return labels, predictions, labels_sent_ar, sent_preds, f1_token, f1_sent"],"metadata":{"id":"KaDgzZ0wuiVE","executionInfo":{"status":"ok","timestamp":1640282675385,"user_tz":-420,"elapsed":388,"user":{"displayName":"Trinh Truong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GibwjDAT5JHasAFlEGN-kjgr2JnHi7XIqtdSxt4=s64","userId":"05537025703764185240"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["### Multi-head model"],"metadata":{"id":"59hFBZ5Uujek"}},{"cell_type":"code","source":["NUM_FILTERS = 10\n","EMBEDDING_SIZE = 768\n","window_sizes=(1,2,3,5)"],"metadata":{"id":"_VzsqaIm2sme","executionInfo":{"status":"ok","timestamp":1640282742449,"user_tz":-420,"elapsed":523,"user":{"displayName":"Trinh Truong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GibwjDAT5JHasAFlEGN-kjgr2JnHi7XIqtdSxt4=s64","userId":"05537025703764185240"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["class Roberta_LSTMCRF_CNN(RobertaPreTrainedModel):\n","\n","    _keys_to_ignore_on_load_unexpected = [r\"pooler\"]\n","    _keys_to_ignore_on_load_missing = [r\"position_ids\"]\n","\n","    def __init__(self, config, alpha=0.01):\n","        super().__init__(config)\n","        self.num_labels = config.num_labels\n","        self.alpha = alpha\n","\n","        self.roberta = RobertaModel(config, add_pooling_layer=False)\n","        classifier_dropout = (\n","            config.classifier_dropout if config.classifier_dropout is not None else config.hidden_dropout_prob\n","        )\n","        self.dropout = nn.Dropout(classifier_dropout)\n","        self.bilstm = nn.LSTM(config.hidden_size, (config.hidden_size) // 2, dropout=0.5, batch_first=True, bidirectional=True)\n","        self.classifier = nn.Linear(config.hidden_size, self.num_labels)\n","\n","        self.crf = CRF(num_tags=self.num_labels, batch_first=True)\n","\n","        self.convs = nn.ModuleList([nn.Conv2d(1, NUM_FILTERS, [window_size, EMBEDDING_SIZE], padding=(window_size - 1, 0)) for window_size in window_sizes])\n","        self.fc = nn.Linear(NUM_FILTERS * len(window_sizes), 3)\n","        self.post_init()\n","\n","    def forward(\n","        self,\n","        input_ids=None,\n","        attention_mask=None,\n","        token_type_ids=None,\n","        position_ids=None,\n","        head_mask=None,\n","        inputs_embeds=None,\n","        labels=None,\n","        labels_sent=None,\n","        output_attentions=None,\n","        output_hidden_states=None,\n","        return_dict=None,\n","    ):\n","        r\"\"\"\n","        labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size, sequence_length)`, `optional`):\n","            Labels for computing the token classification loss. Indices should be in ``[0, ..., config.num_labels -\n","            1]``.\n","        \"\"\"\n","        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n","\n","        outputs = self.roberta(\n","            input_ids,\n","            attention_mask=attention_mask,\n","            token_type_ids=token_type_ids,\n","            position_ids=position_ids,\n","            head_mask=head_mask,\n","            inputs_embeds=inputs_embeds,\n","            output_attentions=output_attentions,\n","            output_hidden_states=True,\n","            return_dict=return_dict,\n","        )\n","\n","        sequence_output = outputs[0]\n","        sequence_output = self.dropout(sequence_output)\n","        lstm_output, hc = self.bilstm(sequence_output)\n","        logits_lstm = self.classifier(lstm_output)\n","\n","        cls_output = torch.cat((outputs[1][-1][:,0, ...],outputs[1][-2][:,0, ...], outputs[1][-3][:,0, ...], outputs[1][-4][:,0, ...]),-1)\n","\n","        xs = []\n","        for conv in self.convs:\n","            x2 = F.relu(conv(outputs[0].unsqueeze(1)))\n","            x2 = torch.squeeze(x2, -1)\n","            x2 = F.max_pool1d(x2, x2.size(2))\n","            xs.append(x2)\n","        x = torch.cat(xs, 2)       \n","        x = x.view(x.size(0), -1)\n","        logits = self.fc(x)\n","\n","        loss_cls = nn.CrossEntropyLoss()\n","        loss_cls =  loss_cls(logits, labels_sent.squeeze(1))\n","\n","        loss = None\n","        if labels is not None:\n","            # print(labels)\n","            labels[labels==-100] = 0\n","            log_likelihood, tags = self.crf(logits_lstm, labels), self.crf.decode(logits_lstm)\n","            loss = 0 - log_likelihood\n","        else:\n","            tags = self.crf.decode(logits_lstm)\n","        tags = torch.Tensor(tags)\n","        tags = tags.to(device)\n","\n","        if not return_dict:\n","            output = (tags,) + outputs[2:]\n","            return (((self.alpha * loss)+loss_cls,) + output) if loss is not None else output\n","\n","        return (self.alpha * loss)+loss_cls, tags, logits, logits_lstm\n","\n","checkpoint_path = './checkpoints/Roberta_LSTMCRF_CNN.pth'\n","model = Roberta_LSTMCRF_CNN.from_pretrained('vinai/phobert-base', config=config, alpha=0.01)\n","model.to(device)"],"metadata":{"id":"CosPSuKFuv7r","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["8525dc9e42714e7b956566591b333a68","3b26069809f744d4bff3fb0e3855bf1b","9fe2daed5713473aad60f170629a6daf","eee2a10dc173472491d74e28d87d626e","515b2e6b53484a849a4420bcef578179","6cf55af8597641eaba39d7e8c57478e4","4439960faa744b308e39df2648fed8a0","b1f6395b70da45119ee565e914a27b40","34435adef75746248d08bddb901ad973","839ff49e51214c8cabd0152221aed72e","6d005a69a52a47c0b6bc5ee7f86b044c"]},"executionInfo":{"status":"ok","timestamp":1640282778553,"user_tz":-420,"elapsed":31460,"user":{"displayName":"Trinh Truong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GibwjDAT5JHasAFlEGN-kjgr2JnHi7XIqtdSxt4=s64","userId":"05537025703764185240"}},"outputId":"e4dd1872-e6a2-4f16-e2fc-c051e1dbbf8f"},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8525dc9e42714e7b956566591b333a68","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/518M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n","  \"num_layers={}\".format(dropout, num_layers))\n","Some weights of the model checkpoint at vinai/phobert-base were not used when initializing Roberta_LSTMCRF_CNN: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight']\n","- This IS expected if you are initializing Roberta_LSTMCRF_CNN from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing Roberta_LSTMCRF_CNN from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of Roberta_LSTMCRF_CNN were not initialized from the model checkpoint at vinai/phobert-base and are newly initialized: ['crf.start_transitions', 'convs.3.bias', 'bilstm.bias_hh_l0', 'bilstm.weight_ih_l0', 'convs.0.weight', 'bilstm.weight_hh_l0', 'bilstm.bias_hh_l0_reverse', 'convs.0.bias', 'crf.transitions', 'convs.2.weight', 'convs.2.bias', 'classifier.weight', 'bilstm.bias_ih_l0_reverse', 'convs.1.bias', 'fc.weight', 'convs.3.weight', 'bilstm.weight_hh_l0_reverse', 'bilstm.bias_ih_l0', 'classifier.bias', 'convs.1.weight', 'fc.bias', 'crf.end_transitions', 'bilstm.weight_ih_l0_reverse']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["Roberta_LSTMCRF_CNN(\n","  (roberta): RobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(64001, 768, padding_idx=1)\n","      (position_embeddings): Embedding(258, 768, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): RobertaEncoder(\n","      (layer): ModuleList(\n","        (0): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (dropout): Dropout(p=0.5, inplace=False)\n","  (bilstm): LSTM(768, 384, batch_first=True, dropout=0.5, bidirectional=True)\n","  (classifier): Linear(in_features=768, out_features=5, bias=True)\n","  (crf): CRF(num_tags=5)\n","  (convs): ModuleList(\n","    (0): Conv2d(1, 10, kernel_size=(1, 768), stride=(1, 1))\n","    (1): Conv2d(1, 10, kernel_size=(2, 768), stride=(1, 1), padding=(1, 0))\n","    (2): Conv2d(1, 10, kernel_size=(3, 768), stride=(1, 1), padding=(2, 0))\n","    (3): Conv2d(1, 10, kernel_size=(5, 768), stride=(1, 1), padding=(4, 0))\n","  )\n","  (fc): Linear(in_features=40, out_features=3, bias=True)\n",")"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["model.alpha"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5FFUaouPeIfz","executionInfo":{"status":"ok","timestamp":1640282779974,"user_tz":-420,"elapsed":5,"user":{"displayName":"Trinh Truong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GibwjDAT5JHasAFlEGN-kjgr2JnHi7XIqtdSxt4=s64","userId":"05537025703764185240"}},"outputId":"51a3c303-9dee-4720-d940-4024da034e18"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.01"]},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","source":["### Traning setting"],"metadata":{"id":"qp6uSVHouxmr"}},{"cell_type":"code","source":["param_optimizer = list(model.named_parameters())\n","no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n","optimizer_grouped_parameters = [\n","    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n","    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n","]\n","num_train_optimization_steps = int(args.epochs*len(train_dataset)/BATCHSIZE_TRAIN/args.accumulation_steps)\n","optimizer = AdamW(optimizer_grouped_parameters, lr=LEARNING_RATE, correct_bias=False)  # To reproduce BertAdam specific behavior set correct_bias=False\n","scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=100, num_training_steps=num_train_optimization_steps)  # PyTorch scheduler\n","# scheduler0 = get_constant_schedule(optimizer)  # PyTorch scheduler\n","\n","print(\"Learning rate: \", LEARNING_RATE)\n","print(\"num_train_optimization_steps:\", num_train_optimization_steps)\n","\n","tsfm = model.roberta\n","for child in tsfm.children():\n","    for param in child.parameters():\n","        if not param.requires_grad:\n","            print(\"whoopsies\")\n","        param.requires_grad = False\n","frozen = True"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HF6OUTy5uzKZ","executionInfo":{"status":"ok","timestamp":1640282779975,"user_tz":-420,"elapsed":4,"user":{"displayName":"Trinh Truong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GibwjDAT5JHasAFlEGN-kjgr2JnHi7XIqtdSxt4=s64","userId":"05537025703764185240"}},"outputId":"51e03c2f-9686-4b63-f761-1c742833a434"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Learning rate:  1e-05\n","num_train_optimization_steps: 7315\n"]}]},{"cell_type":"markdown","source":["### Train & validate\n"],"metadata":{"id":"hzM1O62Puzqa"}},{"cell_type":"code","source":["f1_best = 0\n","\n","for epoch in range(NUM_EPOCH):\n","    if epoch > 0 and frozen:\n","        for child in tsfm.children():\n","            for param in child.parameters():\n","                param.requires_grad = True\n","        frozen = False\n","        try:\n","            del scheduler0\n","        except:\n","            pass\n","        torch.cuda.empty_cache()\n","\n","    st = time.time()\n","    print(f\"Training epoch: {epoch + 1}\")\n","    train_crf(epoch)\n","    labels, predictions, labels_sent_ar, sent_preds, f1_token, f1_sent  = valid_crf(model, valid_loader)\n","    if (f1_token+f1_sent)/2 > f1_best:\n","        f1_best = (f1_token+f1_sent)/2\n","        print(f'New best f1 {f1_best}')\n","\n","    print('report for tagging\\n', classification_report([labels], [predictions]))\n","    print('report for classification\\n', metrics.classification_report(labels_sent_ar, sent_preds))\n","\n","    # save best model\n","    torch.save(model.state_dict(), checkpoint_path)\n","    for param_group in optimizer.param_groups:\n","        print('Current leanring rate: ',param_group['lr'])\n","    print('Time: ',time.time() - st)\n","    print('======================================================')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LnWV016eu3L0","outputId":"96224132-ced7-4f80-88f0-f4cd9e88fdd1","executionInfo":{"status":"ok","timestamp":1640288692783,"user_tz":-420,"elapsed":5906598,"user":{"displayName":"Trinh Truong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GibwjDAT5JHasAFlEGN-kjgr2JnHi7XIqtdSxt4=s64","userId":"05537025703764185240"}}},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torchcrf/__init__.py:249: UserWarning: where received a uint8 condition tensor. This behavior is deprecated and will be removed in a future version of PyTorch. Use a boolean condition instead. (Triggered internally at  ../aten/src/ATen/native/TensorCompare.cpp:328.)\n","  score = torch.where(mask[i].unsqueeze(1), next_score, score)\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 4.777522579284564 F1 tagging: 0.0011207379628432258 F1 classification: 0.38767123287671235\n","Train loss: 1.6392974604617108 F1 tagging: 0.0 F1 classification: 0.6043956043956044\n","New best f1 0.3021978021978022\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["report for tagging\n","               precision    recall  f1-score   support\n","\n","         DES       0.00      0.00      0.00      2259\n","         PRI       0.00      0.00      0.00       193\n","\n","   micro avg       0.00      0.00      0.00      2452\n","   macro avg       0.00      0.00      0.00      2452\n","weighted avg       0.00      0.00      0.00      2452\n","\n","report for classification\n","               precision    recall  f1-score   support\n","\n","           0       0.70      0.65      0.67       321\n","           1       0.45      0.39      0.42       207\n","           2       0.60      0.76      0.67       200\n","\n","    accuracy                           0.60       728\n","   macro avg       0.58      0.60      0.59       728\n","weighted avg       0.60      0.60      0.60       728\n","\n","Current leanring rate:  9.632709632709634e-06\n","Current leanring rate:  9.632709632709634e-06\n","Time:  215.10480093955994\n","======================================================\n","Training epoch: 2\n","Train loss: 1.4780814699930687 F1 tagging: 0.5253189679614403 F1 classification: 0.6513698630136986\n","Train loss: 0.8952802496624517 F1 tagging: 0.6484405082787832 F1 classification: 0.7747252747252747\n","New best f1 0.711582891502029\n","report for tagging\n","               precision    recall  f1-score   support\n","\n","         DES       0.62      0.74      0.67      2259\n","         PRI       0.32      0.03      0.06       193\n","\n","   micro avg       0.61      0.69      0.65      2452\n","   macro avg       0.47      0.39      0.37      2452\n","weighted avg       0.59      0.69      0.63      2452\n","\n","report for classification\n","               precision    recall  f1-score   support\n","\n","           0       0.82      0.87      0.85       321\n","           1       0.64      0.53      0.58       207\n","           2       0.81      0.87      0.84       200\n","\n","    accuracy                           0.77       728\n","   macro avg       0.76      0.76      0.75       728\n","weighted avg       0.77      0.77      0.77       728\n","\n","Current leanring rate:  9.126819126819127e-06\n","Current leanring rate:  9.126819126819127e-06\n","Time:  305.3441059589386\n","======================================================\n","Training epoch: 3\n","Train loss: 1.0038701882101084 F1 tagging: 0.654119067988526 F1 classification: 0.8089041095890411\n","Train loss: 0.7087711615713088 F1 tagging: 0.6781196903907872 F1 classification: 0.7815934065934066\n","New best f1 0.7298565484920969\n","report for tagging\n","               precision    recall  f1-score   support\n","\n","         DES       0.65      0.78      0.71      2259\n","         PRI       0.23      0.12      0.16       193\n","\n","   micro avg       0.63      0.73      0.68      2452\n","   macro avg       0.44      0.45      0.43      2452\n","weighted avg       0.61      0.73      0.67      2452\n","\n","report for classification\n","               precision    recall  f1-score   support\n","\n","           0       0.87      0.79      0.83       321\n","           1       0.60      0.72      0.66       207\n","           2       0.88      0.82      0.85       200\n","\n","    accuracy                           0.78       728\n","   macro avg       0.78      0.78      0.78       728\n","weighted avg       0.80      0.78      0.79       728\n","\n","Current leanring rate:  8.62092862092862e-06\n","Current leanring rate:  8.62092862092862e-06\n","Time:  298.34448075294495\n","======================================================\n","Training epoch: 4\n","Train loss: 0.7979764027954781 F1 tagging: 0.7117935115282595 F1 classification: 0.8363013698630137\n","Train loss: 0.6404382883683666 F1 tagging: 0.7621483375959079 F1 classification: 0.7843406593406593\n","New best f1 0.7732444984682836\n","report for tagging\n","               precision    recall  f1-score   support\n","\n","         DES       0.78      0.83      0.80      2259\n","         PRI       0.27      0.31      0.29       193\n","\n","   micro avg       0.74      0.79      0.76      2452\n","   macro avg       0.53      0.57      0.55      2452\n","weighted avg       0.74      0.79      0.76      2452\n","\n","report for classification\n","               precision    recall  f1-score   support\n","\n","           0       0.87      0.79      0.83       321\n","           1       0.60      0.75      0.67       207\n","           2       0.91      0.81      0.85       200\n","\n","    accuracy                           0.78       728\n","   macro avg       0.79      0.78      0.78       728\n","weighted avg       0.80      0.78      0.79       728\n","\n","Current leanring rate:  8.115038115038114e-06\n","Current leanring rate:  8.115038115038114e-06\n","Time:  301.6514081954956\n","======================================================\n","Training epoch: 5\n","Train loss: 0.6774643380756248 F1 tagging: 0.7636604369302846 F1 classification: 0.8565068493150685\n","Train loss: 0.6144722915448986 F1 tagging: 0.7978490340569607 F1 classification: 0.7870879120879121\n","New best f1 0.7924684730724364\n","report for tagging\n","               precision    recall  f1-score   support\n","\n","         DES       0.83      0.85      0.84      2259\n","         PRI       0.33      0.42      0.37       193\n","\n","   micro avg       0.78      0.82      0.80      2452\n","   macro avg       0.58      0.64      0.60      2452\n","weighted avg       0.79      0.82      0.80      2452\n","\n","report for classification\n","               precision    recall  f1-score   support\n","\n","           0       0.87      0.80      0.83       321\n","           1       0.61      0.73      0.67       207\n","           2       0.89      0.82      0.85       200\n","\n","    accuracy                           0.79       728\n","   macro avg       0.79      0.78      0.79       728\n","weighted avg       0.80      0.79      0.79       728\n","\n","Current leanring rate:  7.60914760914761e-06\n","Current leanring rate:  7.60914760914761e-06\n","Time:  303.8616750240326\n","======================================================\n","Training epoch: 6\n","Train loss: 0.5723962795652755 F1 tagging: 0.7904853679565857 F1 classification: 0.8917808219178083\n","Train loss: 0.6220016147491041 F1 tagging: 0.8144796380090498 F1 classification: 0.7815934065934066\n","New best f1 0.7980365223012282\n","report for tagging\n","               precision    recall  f1-score   support\n","\n","         DES       0.84      0.87      0.86      2259\n","         PRI       0.35      0.54      0.43       193\n","\n","   micro avg       0.79      0.84      0.81      2452\n","   macro avg       0.60      0.71      0.64      2452\n","weighted avg       0.80      0.84      0.82      2452\n","\n","report for classification\n","               precision    recall  f1-score   support\n","\n","           0       0.90      0.75      0.82       321\n","           1       0.59      0.78      0.67       207\n","           2       0.88      0.84      0.86       200\n","\n","    accuracy                           0.78       728\n","   macro avg       0.79      0.79      0.78       728\n","weighted avg       0.81      0.78      0.79       728\n","\n","Current leanring rate:  7.103257103257104e-06\n","Current leanring rate:  7.103257103257104e-06\n","Time:  299.96693086624146\n","======================================================\n","Training epoch: 7\n","Train loss: 0.5076838041413321 F1 tagging: 0.8168374299702216 F1 classification: 0.9044520547945205\n","Train loss: 0.6253258191294723 F1 tagging: 0.8258726089528692 F1 classification: 0.7925824175824174\n","New best f1 0.8092275132676433\n","report for tagging\n","               precision    recall  f1-score   support\n","\n","         DES       0.85      0.88      0.87      2259\n","         PRI       0.37      0.56      0.45       193\n","\n","   micro avg       0.80      0.85      0.83      2452\n","   macro avg       0.61      0.72      0.66      2452\n","weighted avg       0.82      0.85      0.83      2452\n","\n","report for classification\n","               precision    recall  f1-score   support\n","\n","           0       0.88      0.79      0.83       321\n","           1       0.62      0.74      0.67       207\n","           2       0.89      0.85      0.87       200\n","\n","    accuracy                           0.79       728\n","   macro avg       0.80      0.79      0.79       728\n","weighted avg       0.81      0.79      0.80       728\n","\n","Current leanring rate:  6.597366597366598e-06\n","Current leanring rate:  6.597366597366598e-06\n","Time:  300.9644339084625\n","======================================================\n","Training epoch: 8\n","Train loss: 0.4435625052615388 F1 tagging: 0.8257804632426988 F1 classification: 0.9263698630136986\n","Train loss: 0.6506009663731515 F1 tagging: 0.8263283108643933 F1 classification: 0.7967032967032966\n","New best f1 0.811515803783845\n","report for tagging\n","               precision    recall  f1-score   support\n","\n","         DES       0.85      0.87      0.86      2259\n","         PRI       0.43      0.63      0.51       193\n","\n","   micro avg       0.80      0.85      0.83      2452\n","   macro avg       0.64      0.75      0.68      2452\n","weighted avg       0.82      0.85      0.83      2452\n","\n","report for classification\n","               precision    recall  f1-score   support\n","\n","           0       0.90      0.76      0.82       321\n","           1       0.61      0.82      0.70       207\n","           2       0.92      0.84      0.88       200\n","\n","    accuracy                           0.80       728\n","   macro avg       0.81      0.80      0.80       728\n","weighted avg       0.83      0.80      0.80       728\n","\n","Current leanring rate:  6.091476091476092e-06\n","Current leanring rate:  6.091476091476092e-06\n","Time:  302.9183495044708\n","======================================================\n","Training epoch: 9\n","Train loss: 0.39215733247668777 F1 tagging: 0.8441361150496253 F1 classification: 0.9352739726027397\n","Train loss: 0.6529303559685474 F1 tagging: 0.8400793650793651 F1 classification: 0.8063186813186813\n","New best f1 0.8231990231990232\n","report for tagging\n","               precision    recall  f1-score   support\n","\n","         DES       0.86      0.88      0.87      2259\n","         PRI       0.47      0.64      0.54       193\n","\n","   micro avg       0.82      0.86      0.84      2452\n","   macro avg       0.66      0.76      0.71      2452\n","weighted avg       0.83      0.86      0.84      2452\n","\n","report for classification\n","               precision    recall  f1-score   support\n","\n","           0       0.87      0.83      0.85       321\n","           1       0.64      0.76      0.69       207\n","           2       0.93      0.82      0.87       200\n","\n","    accuracy                           0.81       728\n","   macro avg       0.81      0.80      0.80       728\n","weighted avg       0.82      0.81      0.81       728\n","\n","Current leanring rate:  5.585585585585585e-06\n","Current leanring rate:  5.585585585585585e-06\n","Time:  303.74753499031067\n","======================================================\n","Training epoch: 10\n","Train loss: 0.3511193900688054 F1 tagging: 0.8581022640549478 F1 classification: 0.9544520547945206\n","Train loss: 0.6876497394763507 F1 tagging: 0.8496031746031746 F1 classification: 0.7884615384615384\n","report for tagging\n","               precision    recall  f1-score   support\n","\n","         DES       0.86      0.89      0.87      2259\n","         PRI       0.53      0.69      0.60       193\n","\n","   micro avg       0.83      0.87      0.85      2452\n","   macro avg       0.70      0.79      0.74      2452\n","weighted avg       0.83      0.87      0.85      2452\n","\n","report for classification\n","               precision    recall  f1-score   support\n","\n","           0       0.88      0.78      0.83       321\n","           1       0.60      0.79      0.68       207\n","           2       0.94      0.80      0.86       200\n","\n","    accuracy                           0.79       728\n","   macro avg       0.81      0.79      0.79       728\n","weighted avg       0.82      0.79      0.80       728\n","\n","Current leanring rate:  5.079695079695081e-06\n","Current leanring rate:  5.079695079695081e-06\n","Time:  297.87307357788086\n","======================================================\n","Training epoch: 11\n","Train loss: 0.33398861446200984 F1 tagging: 0.8676590538336053 F1 classification: 0.9530821917808219\n","Train loss: 0.6973560899700765 F1 tagging: 0.8550200803212851 F1 classification: 0.7912087912087912\n","report for tagging\n","               precision    recall  f1-score   support\n","\n","         DES       0.87      0.88      0.88      2259\n","         PRI       0.59      0.70      0.64       193\n","\n","   micro avg       0.84      0.87      0.86      2452\n","   macro avg       0.73      0.79      0.76      2452\n","weighted avg       0.85      0.87      0.86      2452\n","\n","report for classification\n","               precision    recall  f1-score   support\n","\n","           0       0.87      0.80      0.84       321\n","           1       0.62      0.71      0.66       207\n","           2       0.88      0.85      0.87       200\n","\n","    accuracy                           0.79       728\n","   macro avg       0.79      0.79      0.79       728\n","weighted avg       0.80      0.79      0.80       728\n","\n","Current leanring rate:  4.573804573804574e-06\n","Current leanring rate:  4.573804573804574e-06\n","Time:  298.4229545593262\n","======================================================\n","Training epoch: 12\n","Train loss: 0.296443147253092 F1 tagging: 0.8741897616495686 F1 classification: 0.9657534246575342\n","Train loss: 0.7026305552162639 F1 tagging: 0.8582375478927203 F1 classification: 0.7953296703296703\n","New best f1 0.8267836091111953\n","report for tagging\n","               precision    recall  f1-score   support\n","\n","         DES       0.87      0.88      0.88      2259\n","         PRI       0.60      0.71      0.65       193\n","\n","   micro avg       0.85      0.87      0.86      2452\n","   macro avg       0.74      0.80      0.76      2452\n","weighted avg       0.85      0.87      0.86      2452\n","\n","report for classification\n","               precision    recall  f1-score   support\n","\n","           0       0.87      0.80      0.83       321\n","           1       0.62      0.74      0.68       207\n","           2       0.91      0.84      0.87       200\n","\n","    accuracy                           0.80       728\n","   macro avg       0.80      0.79      0.79       728\n","weighted avg       0.81      0.80      0.80       728\n","\n","Current leanring rate:  4.067914067914068e-06\n","Current leanring rate:  4.067914067914068e-06\n","Time:  298.5617673397064\n","======================================================\n","Training epoch: 13\n","Train loss: 0.27148157632718345 F1 tagging: 0.8884344002454239 F1 classification: 0.9732876712328767\n","Train loss: 0.732463240521131 F1 tagging: 0.8604604604604603 F1 classification: 0.7843406593406593\n","report for tagging\n","               precision    recall  f1-score   support\n","\n","         DES       0.87      0.89      0.88      2259\n","         PRI       0.62      0.73      0.67       193\n","\n","   micro avg       0.85      0.88      0.86      2452\n","   macro avg       0.75      0.81      0.77      2452\n","weighted avg       0.85      0.88      0.86      2452\n","\n","report for classification\n","               precision    recall  f1-score   support\n","\n","           0       0.86      0.79      0.82       321\n","           1       0.61      0.72      0.66       207\n","           2       0.89      0.84      0.87       200\n","\n","    accuracy                           0.78       728\n","   macro avg       0.79      0.78      0.78       728\n","weighted avg       0.80      0.78      0.79       728\n","\n","Current leanring rate:  3.562023562023562e-06\n","Current leanring rate:  3.562023562023562e-06\n","Time:  297.95878052711487\n","======================================================\n","Training epoch: 14\n","Train loss: 0.261626645892042 F1 tagging: 0.8940139401394013 F1 classification: 0.9715753424657534\n","Train loss: 0.7338673335674045 F1 tagging: 0.8668805132317563 F1 classification: 0.7898351648351648\n","New best f1 0.8283578390334605\n","report for tagging\n","               precision    recall  f1-score   support\n","\n","         DES       0.87      0.89      0.88      2259\n","         PRI       0.64      0.74      0.68       193\n","\n","   micro avg       0.85      0.88      0.87      2452\n","   macro avg       0.76      0.81      0.78      2452\n","weighted avg       0.85      0.88      0.87      2452\n","\n","report for classification\n","               precision    recall  f1-score   support\n","\n","           0       0.89      0.77      0.82       321\n","           1       0.61      0.77      0.68       207\n","           2       0.90      0.84      0.87       200\n","\n","    accuracy                           0.79       728\n","   macro avg       0.80      0.79      0.79       728\n","weighted avg       0.81      0.79      0.80       728\n","\n","Current leanring rate:  3.0561330561330565e-06\n","Current leanring rate:  3.0561330561330565e-06\n","Time:  299.0547049045563\n","======================================================\n","Training epoch: 15\n","Train loss: 0.2440127022972662 F1 tagging: 0.8922398317689901 F1 classification: 0.9791095890410959\n","Train loss: 0.7486810508173901 F1 tagging: 0.8642172523961661 F1 classification: 0.7994505494505495\n","New best f1 0.8318339009233577\n","report for tagging\n","               precision    recall  f1-score   support\n","\n","         DES       0.86      0.89      0.88      2259\n","         PRI       0.66      0.74      0.70       193\n","\n","   micro avg       0.85      0.88      0.86      2452\n","   macro avg       0.76      0.82      0.79      2452\n","weighted avg       0.85      0.88      0.86      2452\n","\n","report for classification\n","               precision    recall  f1-score   support\n","\n","           0       0.85      0.84      0.84       321\n","           1       0.64      0.70      0.67       207\n","           2       0.91      0.84      0.87       200\n","\n","    accuracy                           0.80       728\n","   macro avg       0.80      0.79      0.80       728\n","weighted avg       0.81      0.80      0.80       728\n","\n","Current leanring rate:  2.5502425502425506e-06\n","Current leanring rate:  2.5502425502425506e-06\n","Time:  299.1858777999878\n","======================================================\n","Training epoch: 16\n","Train loss: 0.23552927835142776 F1 tagging: 0.8988107443100266 F1 classification: 0.9791095890410959\n","Train loss: 0.7743126006674145 F1 tagging: 0.8690237042989151 F1 classification: 0.7898351648351648\n","report for tagging\n","               precision    recall  f1-score   support\n","\n","         DES       0.87      0.89      0.88      2259\n","         PRI       0.66      0.74      0.70       193\n","\n","   micro avg       0.86      0.88      0.87      2452\n","   macro avg       0.77      0.82      0.79      2452\n","weighted avg       0.86      0.88      0.87      2452\n","\n","report for classification\n","               precision    recall  f1-score   support\n","\n","           0       0.88      0.78      0.83       321\n","           1       0.61      0.75      0.67       207\n","           2       0.89      0.84      0.87       200\n","\n","    accuracy                           0.79       728\n","   macro avg       0.79      0.79      0.79       728\n","weighted avg       0.81      0.79      0.80       728\n","\n","Current leanring rate:  2.0443520443520446e-06\n","Current leanring rate:  2.0443520443520446e-06\n","Time:  300.3493468761444\n","======================================================\n","Training epoch: 17\n","Train loss: 0.2253033600135209 F1 tagging: 0.9024377726456247 F1 classification: 0.9811643835616438\n","Train loss: 0.7837658453487105 F1 tagging: 0.8655227454110136 F1 classification: 0.7953296703296703\n","report for tagging\n","               precision    recall  f1-score   support\n","\n","         DES       0.86      0.90      0.88      2259\n","         PRI       0.67      0.74      0.70       193\n","\n","   micro avg       0.85      0.88      0.87      2452\n","   macro avg       0.76      0.82      0.79      2452\n","weighted avg       0.85      0.88      0.87      2452\n","\n","report for classification\n","               precision    recall  f1-score   support\n","\n","           0       0.85      0.82      0.83       321\n","           1       0.63      0.71      0.67       207\n","           2       0.91      0.84      0.88       200\n","\n","    accuracy                           0.80       728\n","   macro avg       0.80      0.79      0.79       728\n","weighted avg       0.80      0.80      0.80       728\n","\n","Current leanring rate:  1.5384615384615387e-06\n","Current leanring rate:  1.5384615384615387e-06\n","Time:  301.29324531555176\n","======================================================\n","Training epoch: 18\n","Train loss: 0.21779715984243236 F1 tagging: 0.904871913342574 F1 classification: 0.9811643835616438\n","Train loss: 0.7830359169466237 F1 tagging: 0.8737903225806453 F1 classification: 0.7898351648351648\n","report for tagging\n","               precision    recall  f1-score   support\n","\n","         DES       0.88      0.89      0.89      2259\n","         PRI       0.69      0.76      0.72       193\n","\n","   micro avg       0.86      0.88      0.87      2452\n","   macro avg       0.78      0.83      0.80      2452\n","weighted avg       0.87      0.88      0.87      2452\n","\n","report for classification\n","               precision    recall  f1-score   support\n","\n","           0       0.85      0.81      0.83       321\n","           1       0.62      0.72      0.67       207\n","           2       0.91      0.83      0.87       200\n","\n","    accuracy                           0.79       728\n","   macro avg       0.79      0.79      0.79       728\n","weighted avg       0.80      0.79      0.79       728\n","\n","Current leanring rate:  1.0325710325710326e-06\n","Current leanring rate:  1.0325710325710326e-06\n","Time:  299.06892132759094\n","======================================================\n","Training epoch: 19\n","Train loss: 0.21094756982710264 F1 tagging: 0.9092682926829267 F1 classification: 0.9852739726027397\n","Train loss: 0.7861137628852093 F1 tagging: 0.8727418707346447 F1 classification: 0.7884615384615384\n","report for tagging\n","               precision    recall  f1-score   support\n","\n","         DES       0.87      0.90      0.89      2259\n","         PRI       0.70      0.76      0.72       193\n","\n","   micro avg       0.86      0.89      0.87      2452\n","   macro avg       0.78      0.83      0.81      2452\n","weighted avg       0.86      0.89      0.87      2452\n","\n","report for classification\n","               precision    recall  f1-score   support\n","\n","           0       0.86      0.79      0.82       321\n","           1       0.61      0.74      0.67       207\n","           2       0.91      0.84      0.88       200\n","\n","    accuracy                           0.79       728\n","   macro avg       0.79      0.79      0.79       728\n","weighted avg       0.80      0.79      0.79       728\n","\n","Current leanring rate:  5.266805266805268e-07\n","Current leanring rate:  5.266805266805268e-07\n","Time:  291.23347783088684\n","======================================================\n","Training epoch: 20\n","Train loss: 0.20948713996434865 F1 tagging: 0.9045128205128204 F1 classification: 0.9849315068493151\n","Train loss: 0.7863039231429306 F1 tagging: 0.8739191634828071 F1 classification: 0.7843406593406593\n","report for tagging\n","               precision    recall  f1-score   support\n","\n","         DES       0.88      0.90      0.89      2259\n","         PRI       0.70      0.76      0.73       193\n","\n","   micro avg       0.86      0.89      0.87      2452\n","   macro avg       0.79      0.83      0.81      2452\n","weighted avg       0.86      0.89      0.87      2452\n","\n","report for classification\n","               precision    recall  f1-score   support\n","\n","           0       0.86      0.79      0.82       321\n","           1       0.61      0.71      0.66       207\n","           2       0.89      0.85      0.87       200\n","\n","    accuracy                           0.78       728\n","   macro avg       0.79      0.78      0.78       728\n","weighted avg       0.80      0.78      0.79       728\n","\n","Current leanring rate:  2.0790020790020793e-08\n","Current leanring rate:  2.0790020790020793e-08\n","Time:  291.1768343448639\n","======================================================\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"UfTdL7L7OFZd"},"execution_count":null,"outputs":[]}]}